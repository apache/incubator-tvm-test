.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_how_to_tune_with_autoscheduler_tune_conv2d_layer_cuda.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_tune_with_autoscheduler_tune_conv2d_layer_cuda.py:


.. _auto-scheduler-conv-gpu:

Auto-scheduling a Convolution Layer for GPU
===========================================
**Author**: `Lianmin Zheng <https://github.com/merrymercy>`_,             `Chengfan Jia <https://github.com/jcf94/>`_

This is a tutorial on how to use the auto-scheduler for GPUs.

Different from the template-based :ref:`autotvm <tutorials-autotvm-sec>` which relies on
manual templates to define the search space, the auto-scheduler does not require any templates.
Users only need to write the computation declaration without any schedule commands or templates.
The auto-scheduler can automatically generate a large search space and
find a good schedule in the space.

We use a convolution layer as an example in this tutorial.

Note that this tutorial will not run on Windows or recent versions of macOS. To
get it to run, you will need to wrap the body of this tutorial in a :code:`if
__name__ == "__main__":` block.


.. code-block:: default


    import os

    import numpy as np
    import tvm
    from tvm import te, auto_scheduler, topi
    from tvm.topi.testing import conv2d_nchw_python







Define the computation
^^^^^^^^^^^^^^^^^^^^^^
To begin with, let us define the computation of a convolution layer.
The function should return the list of input/output tensors.
From these tensors, the auto-scheduler can get the whole computational graph.


.. code-block:: default



    @auto_scheduler.register_workload
    def conv2d_layer(N, H, W, CO, CI, KH, KW, stride, padding):
        data = te.placeholder((N, CI, H, W), name="data")
        kernel = te.placeholder((CO, CI, KH, KW), name="kernel")
        bias = te.placeholder((1, CO, 1, 1), name="bias")
        conv = topi.nn.conv2d_nchw(data, kernel, stride, padding, dilation=1, out_dtype="float32")
        out = topi.nn.relu(conv + bias)
        return [data, kernel, bias, out]








Create the search task
^^^^^^^^^^^^^^^^^^^^^^
We then create a search task for the last convolution layer in the resnet.


.. code-block:: default


    target = tvm.target.Target("cuda")

    # Use the last layer in ResNet-50
    N, H, W, CO, CI, KH, KW, strides, padding = 1, 7, 7, 512, 512, 3, 3, (1, 1), (1, 1)
    task = auto_scheduler.SearchTask(
        func=conv2d_layer, args=(N, H, W, CO, CI, KH, KW, strides, padding), target=target
    )

    # Inspect the computational graph
    print("Computational DAG:")
    print(task.compute_dag)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Computational DAG:
    data = PLACEHOLDER [1, 512, 7, 7]
    pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 8)) && (i3 >= 1)) && (i3 < 8)), data[i0, i1, (i2 - 1), (i3 - 1)], 0f)
    kernel = PLACEHOLDER [512, 512, 3, 3]
    conv2d_nchw(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*kernel[ff, rc, ry, rx])
    bias = PLACEHOLDER [1, 512, 1, 1]
    T_add(ax0, ax1, ax2, ax3) = (conv2d_nchw[ax0, ax1, ax2, ax3] + bias[ax0, ax1, 0, 0])
    compute(i0, i1, i2, i3) = max(T_add[i0, i1, i2, i3], 0f)




Next, we set parameters for the auto-scheduler. These parameters
mainly specify how we do the measurement during the search.

* :code:`measure_ctx` launches a different process for measurement to
  provide isolation. It can protect the master process from GPU crashes
  during measurement and avoid other runtime conflicts.
* :code:`min_repeat_ms` defines the minimum duration of one "repeat" in every measurement.
  This can warmup the GPU, which is necessary to get accurate measurement results.
  Typically, we recommend a value >= 300 ms.
* :code:`num_measure_trials` is the number of measurement trials we can use during the search.
  We only make 10 trials in this tutorial for a fast demonstration. In practice, 1000 is a
  good value for the search to converge. You can do more trials according to your time budget.
* In addition, we use :code:`RecordToFile` to dump measurement records into a file `conv2d.json`.
  The measurement records can be used to query the history best, resume the search,
  and do more analyses later.
* see :any:`auto_scheduler.TuningOptions`,
  :any:`auto_scheduler.LocalRPCMeasureContext` for more parameters.


.. code-block:: default


    log_file = "conv2d.json"
    measure_ctx = auto_scheduler.LocalRPCMeasureContext(min_repeat_ms=300)
    tune_option = auto_scheduler.TuningOptions(
        num_measure_trials=10,  # change this to 1000 to achieve the best performance
        runner=measure_ctx.runner,
        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],
        verbose=2,
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Get devices for measurement successfully!



Run the search
^^^^^^^^^^^^^^
Now we get all inputs ready. Pretty simple, isn't it?
We can kick off the search and let the auto-scheduler do its magic.
After some measurement trials, we can load the best schedule from the log
file and apply it.


.. code-block:: default


    # Run auto-tuning (search)
    task.tune(tune_option)
    # Apply the best schedule
    sch, args = task.apply_best(log_file)

    # Kill the measurement process
    del measure_ctx





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none






We can lower the schedule to see the IR after auto-scheduling.
The auto-scheduler correctly performs optimizations including multi-level tiling,
cooperative fetching, unrolling and operator fusion.


.. code-block:: default


    print("Lowered TIR:")
    print(tvm.lower(sch, args, simple_mode=True))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Lowered TIR:
    @main = primfn(data_1: handle, kernel_1: handle, bias_1: handle, compute_1: handle) -> ()
      attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
      buffers = {bias: Buffer(bias_2: Pointer(float32), float32, [512], []),
                 data: Buffer(data_2: Pointer(float32), float32, [25088], []),
                 compute: Buffer(compute_2: Pointer(float32), float32, [25088], []),
                 kernel: Buffer(kernel_2: Pointer(float32), float32, [2359296], [])}
      buffer_map = {data_1: data, kernel_1: kernel, bias_1: bias, compute_1: compute} {
      attr [IterVar(blockIdx.x: int32, (nullptr), "ThreadIndex", "blockIdx.x")] "thread_extent" = 28;
      allocate(conv2d_nchw: Pointer(local float32), float32, [8]), storage_scope = local;
      allocate(pad_temp.shared: Pointer(shared float32), float32, [54]), storage_scope = shared;
      allocate(kernel.shared: Pointer(shared float32), float32, [2304]), storage_scope = shared;
      attr [IterVar(threadIdx.x: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112 {
        conv2d_nchw_1: Buffer(conv2d_nchw, float32, [4], [], scope="local", align=8)[0] = 0f32
        conv2d_nchw_1[2] = 0f32
        conv2d_nchw_1[4] = 0f32
        conv2d_nchw_1[6] = 0f32
        conv2d_nchw_1[1] = 0f32
        conv2d_nchw_1[3] = 0f32
        conv2d_nchw_1[5] = 0f32
        conv2d_nchw_1[7] = 0f32
        for (rc.outer.outer: int32, 0, 256) {
          let cse_var_1: int32 = (rc.outer.outer*18)
           {
            attr [IterVar(threadIdx.x_1: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            if @tir.likely((threadIdx.x_1 < 54), dtype=bool) {
              pad_temp.shared_1: Buffer(pad_temp.shared, float32, [54], [], scope="shared")[threadIdx.x_1] = @tir.if_then_else(((((3 <= floormod(threadIdx.x_1, 27)) && (floormod(threadIdx.x_1, 27) < 24)) && (1 <= (floormod(blockIdx.x, 7) + floormod(threadIdx.x_1, 3)))) && ((floormod(blockIdx.x, 7) + floormod(threadIdx.x_1, 3)) < 8)), data[((((((rc.outer.outer*98) + (floordiv(threadIdx.x_1, 27)*49)) + (floordiv(floormod(threadIdx.x_1, 27), 3)*7)) + floormod(blockIdx.x, 7)) + floormod(threadIdx.x_1, 3)) - 8)], 0f32, dtype=float32)
            }
            attr [IterVar(threadIdx.x_2: int32, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1: Buffer(kernel.shared, float32, [2304], [], scope="shared")[threadIdx.x_2] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv(threadIdx.x_2, 18)*4608)) + cse_var_1) + floormod(threadIdx.x_2, 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 112)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 56), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 4), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 224)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 112), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 8), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 336)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 168), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 12), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 448)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 224), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 16), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 560)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 280), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 2), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 672)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 336), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 6), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 784)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 392), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 10), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 896)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 448), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 14), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1008)] = kernel[(((((floordiv(blockIdx.x, 7)*589824) + (floordiv(floordiv(threadIdx.x_2, 2), 9)*4608)) + cse_var_1) + floormod(threadIdx.x_2, 18)) + 258048)]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1120)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 560), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 4), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1232)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 616), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 8), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1344)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 672), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 12), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1456)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 728), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 16), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1568)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 784), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 2), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1680)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 840), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 6), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1792)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 896), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 10), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 1904)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 952), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 14), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 2016)] = kernel[(((((floordiv(blockIdx.x, 7)*589824) + (floordiv(floordiv(threadIdx.x_2, 2), 9)*4608)) + cse_var_1) + floormod(threadIdx.x_2, 18)) + 516096)]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            kernel.shared_1[(threadIdx.x_2 + 2128)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 1064), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 4), 18))]
            attr [IterVar(threadIdx.x_2, (nullptr), "ThreadIndex", "threadIdx.x")] "thread_extent" = 112;
            if @tir.likely((threadIdx.x_2 < 64), dtype=bool) {
              kernel.shared_1[(threadIdx.x_2 + 2240)] = kernel[((((floordiv(blockIdx.x, 7)*589824) + (floordiv((floordiv(threadIdx.x_2, 2) + 1120), 9)*4608)) + cse_var_1) + floormod((threadIdx.x_2 + 8), 18))]
            }
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[(floordiv(threadIdx.x, 7)*36)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 576)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1152)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1728)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 18)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 594)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1170)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[(floormod(threadIdx.x, 7)*3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1746)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 577)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1153)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1729)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 19)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 595)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1171)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 1)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1747)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 2)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 578)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1154)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1730)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 20)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 596)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1172)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 2)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1748)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 3)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 579)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1155)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1731)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 21)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 597)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1173)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 3)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1749)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 4)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 580)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1156)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1732)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 22)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 598)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1174)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 4)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1750)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 5)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 581)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1157)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1733)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 23)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 599)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1175)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 5)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1751)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 6)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 582)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1158)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1734)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 24)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 600)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1176)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 6)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1752)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 7)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 583)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1159)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1735)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 25)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 601)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1177)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 7)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1753)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 8)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 584)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1160)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1736)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 26)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 602)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1178)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 8)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1754)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 9)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 585)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1161)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1737)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 27)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 603)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1179)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 27)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1755)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 10)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 586)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1162)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1738)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 28)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 604)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1180)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 28)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1756)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 11)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 587)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1163)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1739)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 29)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 605)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1181)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 29)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1757)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 12)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 588)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1164)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1740)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 30)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 606)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1182)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 30)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1758)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 13)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 589)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1165)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1741)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 31)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 607)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1183)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 31)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1759)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 14)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 590)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1166)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1742)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 32)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 608)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1184)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 32)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1760)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 15)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 591)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1167)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1743)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 33)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 609)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1185)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 33)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1761)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 16)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 592)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1168)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1744)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 34)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 610)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1186)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 34)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1762)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 17)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 593)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1169)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1745)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 35)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 611)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1187)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((floormod(threadIdx.x, 7)*3) + 35)]*kernel.shared_1[((floordiv(threadIdx.x, 7)*36) + 1763)]))
          }
        }
        for (i1.inner: int32, 0, 2) {
          compute[(((((floordiv(blockIdx.x, 7)*6272) + (floordiv(threadIdx.x, 7)*98)) + (i1.inner*49)) + (floormod(threadIdx.x, 7)*7)) + floormod(blockIdx.x, 7))] = max((conv2d_nchw_1[i1.inner] + bias[(((floordiv(blockIdx.x, 7)*128) + (floordiv(threadIdx.x, 7)*2)) + i1.inner)]), 0f32)
          compute[((((((floordiv(blockIdx.x, 7)*6272) + (floordiv(threadIdx.x, 7)*98)) + (i1.inner*49)) + (floormod(threadIdx.x, 7)*7)) + floormod(blockIdx.x, 7)) + 1568)] = max((conv2d_nchw_1[(i1.inner + 2)] + bias[((((floordiv(blockIdx.x, 7)*128) + (floordiv(threadIdx.x, 7)*2)) + i1.inner) + 32)]), 0f32)
          compute[((((((floordiv(blockIdx.x, 7)*6272) + (floordiv(threadIdx.x, 7)*98)) + (i1.inner*49)) + (floormod(threadIdx.x, 7)*7)) + floormod(blockIdx.x, 7)) + 3136)] = max((conv2d_nchw_1[(i1.inner + 4)] + bias[((((floordiv(blockIdx.x, 7)*128) + (floordiv(threadIdx.x, 7)*2)) + i1.inner) + 64)]), 0f32)
          compute[((((((floordiv(blockIdx.x, 7)*6272) + (floordiv(threadIdx.x, 7)*98)) + (i1.inner*49)) + (floormod(threadIdx.x, 7)*7)) + floormod(blockIdx.x, 7)) + 4704)] = max((conv2d_nchw_1[(i1.inner + 6)] + bias[((((floordiv(blockIdx.x, 7)*128) + (floordiv(threadIdx.x, 7)*2)) + i1.inner) + 96)]), 0f32)
        }
      }
    }





Check correctness and evaluate performance
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
We build the binary and check its correctness and performance.


.. code-block:: default


    func = tvm.build(sch, args, target)

    # Check correctness
    data_np = np.random.uniform(size=(N, CI, H, W)).astype(np.float32)
    weight_np = np.random.uniform(size=(CO, CI, KH, KW)).astype(np.float32)
    bias_np = np.random.uniform(size=(1, CO, 1, 1)).astype(np.float32)
    conv_np = conv2d_nchw_python(data_np, weight_np, strides, padding)
    out_np = np.maximum(conv_np + bias_np, 0.0)

    dev = tvm.cuda()
    data_tvm = tvm.nd.array(data_np, device=dev)
    weight_tvm = tvm.nd.array(weight_np, device=dev)
    bias_tvm = tvm.nd.array(bias_np, device=dev)
    out_tvm = tvm.nd.empty(out_np.shape, device=dev)
    func(data_tvm, weight_tvm, bias_tvm, out_tvm)

    # Check results
    np.testing.assert_allclose(out_np, out_tvm.numpy(), rtol=1e-3)

    # Evaluate execution time
    evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)
    print(
        "Execution time of this operator: %.3f ms"
        % (np.median(evaluator(data_tvm, weight_tvm, bias_tvm, out_tvm).results) * 1000)
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Execution time of this operator: 0.413 ms



Using the record file
^^^^^^^^^^^^^^^^^^^^^
During the search, all measurement records are dumped into the record
file "conv2d.json". The measurement records can be used to re-apply search results,
resume the search, and perform other analyses.

Here is an example where we load the best schedule from a file,
print the equivalent python schedule API and CUDA source code.
They can be used for debugging and learning the behavior of the auto-scheduler.


.. code-block:: default


    print("Equivalent python schedule:")
    print(task.print_best(log_file, print_mode="schedule"))

    print("CUDA source code:")
    print(task.print_best(log_file, print_mode="cuda"))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Equivalent python schedule:
    pad_temp_i0, pad_temp_i1, pad_temp_i2, pad_temp_i3 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
    conv2d_nchw_nn, conv2d_nchw_ff, conv2d_nchw_yy, conv2d_nchw_xx, conv2d_nchw_rc, conv2d_nchw_ry, conv2d_nchw_rx = tuple(conv2d_nchw.op.axis) + tuple(conv2d_nchw.op.reduce_axis)
    T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
    compute_i0, compute_i1, compute_i2, compute_i3 = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
    s[T_add].compute_inline()
    conv2d_nchw_nn_o_i, conv2d_nchw_nn_i = s[conv2d_nchw].split(conv2d_nchw_nn, factor=1)
    conv2d_nchw_nn_o_o_i, conv2d_nchw_nn_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_i, factor=1)
    conv2d_nchw_nn_o_o_o_i, conv2d_nchw_nn_o_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_o_i, factor=1)
    conv2d_nchw_nn_o_o_o_o, conv2d_nchw_nn_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_o_o_i, factor=1)
    conv2d_nchw_ff_o_i, conv2d_nchw_ff_i = s[conv2d_nchw].split(conv2d_nchw_ff, factor=2)
    conv2d_nchw_ff_o_o_i, conv2d_nchw_ff_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_i, factor=1)
    conv2d_nchw_ff_o_o_o_i, conv2d_nchw_ff_o_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_o_i, factor=16)
    conv2d_nchw_ff_o_o_o_o, conv2d_nchw_ff_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_o_o_i, factor=4)
    conv2d_nchw_yy_o_i, conv2d_nchw_yy_i = s[conv2d_nchw].split(conv2d_nchw_yy, factor=1)
    conv2d_nchw_yy_o_o_i, conv2d_nchw_yy_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_i, factor=1)
    conv2d_nchw_yy_o_o_o_i, conv2d_nchw_yy_o_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_o_i, factor=7)
    conv2d_nchw_yy_o_o_o_o, conv2d_nchw_yy_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_o_o_i, factor=1)
    conv2d_nchw_xx_o_i, conv2d_nchw_xx_i = s[conv2d_nchw].split(conv2d_nchw_xx, factor=1)
    conv2d_nchw_xx_o_o_i, conv2d_nchw_xx_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_i, factor=1)
    conv2d_nchw_xx_o_o_o_i, conv2d_nchw_xx_o_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_o_i, factor=1)
    conv2d_nchw_xx_o_o_o_o, conv2d_nchw_xx_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_o_o_i, factor=1)
    conv2d_nchw_rc_o_i, conv2d_nchw_rc_i = s[conv2d_nchw].split(conv2d_nchw_rc, factor=1)
    conv2d_nchw_rc_o_o, conv2d_nchw_rc_o_i = s[conv2d_nchw].split(conv2d_nchw_rc_o_i, factor=2)
    conv2d_nchw_ry_o_i, conv2d_nchw_ry_i = s[conv2d_nchw].split(conv2d_nchw_ry, factor=3)
    conv2d_nchw_ry_o_o, conv2d_nchw_ry_o_i = s[conv2d_nchw].split(conv2d_nchw_ry_o_i, factor=1)
    conv2d_nchw_rx_o_i, conv2d_nchw_rx_i = s[conv2d_nchw].split(conv2d_nchw_rx, factor=3)
    conv2d_nchw_rx_o_o, conv2d_nchw_rx_o_i = s[conv2d_nchw].split(conv2d_nchw_rx_o_i, factor=1)
    s[conv2d_nchw].reorder(conv2d_nchw_nn_o_o_o_o, conv2d_nchw_ff_o_o_o_o, conv2d_nchw_yy_o_o_o_o, conv2d_nchw_xx_o_o_o_o, conv2d_nchw_nn_o_o_o_i, conv2d_nchw_ff_o_o_o_i, conv2d_nchw_yy_o_o_o_i, conv2d_nchw_xx_o_o_o_i, conv2d_nchw_nn_o_o_i, conv2d_nchw_ff_o_o_i, conv2d_nchw_yy_o_o_i, conv2d_nchw_xx_o_o_i, conv2d_nchw_rc_o_o, conv2d_nchw_ry_o_o, conv2d_nchw_rx_o_o, conv2d_nchw_rc_o_i, conv2d_nchw_ry_o_i, conv2d_nchw_rx_o_i, conv2d_nchw_nn_o_i, conv2d_nchw_ff_o_i, conv2d_nchw_yy_o_i, conv2d_nchw_xx_o_i, conv2d_nchw_rc_i, conv2d_nchw_ry_i, conv2d_nchw_rx_i, conv2d_nchw_nn_i, conv2d_nchw_ff_i, conv2d_nchw_yy_i, conv2d_nchw_xx_i)
    compute_i0_o_i, compute_i0_i = s[compute].split(compute_i0, factor=1)
    compute_i0_o_o_i, compute_i0_o_i = s[compute].split(compute_i0_o_i, factor=1)
    compute_i0_o_o_o, compute_i0_o_o_i = s[compute].split(compute_i0_o_o_i, factor=1)
    compute_i1_o_i, compute_i1_i = s[compute].split(compute_i1, factor=2)
    compute_i1_o_o_i, compute_i1_o_i = s[compute].split(compute_i1_o_i, factor=16)
    compute_i1_o_o_o, compute_i1_o_o_i = s[compute].split(compute_i1_o_o_i, factor=4)
    compute_i2_o_i, compute_i2_i = s[compute].split(compute_i2, factor=1)
    compute_i2_o_o_i, compute_i2_o_i = s[compute].split(compute_i2_o_i, factor=7)
    compute_i2_o_o_o, compute_i2_o_o_i = s[compute].split(compute_i2_o_o_i, factor=1)
    compute_i3_o_i, compute_i3_i = s[compute].split(compute_i3, factor=1)
    compute_i3_o_o_i, compute_i3_o_i = s[compute].split(compute_i3_o_i, factor=1)
    compute_i3_o_o_o, compute_i3_o_o_i = s[compute].split(compute_i3_o_o_i, factor=1)
    s[compute].reorder(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o, compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i, compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i, compute_i0_i, compute_i1_i, compute_i2_i, compute_i3_i)
    s[conv2d_nchw].compute_at(s[compute], compute_i3_o_i)
    kernel_shared = s.cache_read(kernel, "shared", [conv2d_nchw])
    kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3 = tuple(kernel_shared.op.axis)
    s[kernel_shared].compute_at(s[conv2d_nchw], conv2d_nchw_rx_o_o)
    pad_temp_shared = s.cache_read(pad_temp, "shared", [conv2d_nchw])
    pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3 = tuple(pad_temp_shared.op.axis)
    s[pad_temp_shared].compute_at(s[conv2d_nchw], conv2d_nchw_rx_o_o)
    s[pad_temp].compute_inline()
    compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused = s[compute].fuse(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o)
    s[compute].bind(compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused, te.thread_axis("blockIdx.x"))
    compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused = s[compute].fuse(compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i)
    s[compute].bind(compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused, te.thread_axis("vthread"))
    compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused = s[compute].fuse(compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i)
    s[compute].bind(compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused, te.thread_axis("threadIdx.x"))
    kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[kernel_shared].fuse(kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3)
    kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=1)
    s[kernel_shared].vectorize(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
    kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=112)
    s[kernel_shared].bind(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis("threadIdx.x"))
    pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[pad_temp_shared].fuse(pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3)
    pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=1)
    s[pad_temp_shared].vectorize(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
    pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=112)
    s[pad_temp_shared].bind(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis("threadIdx.x"))
    s[conv2d_nchw].pragma(conv2d_nchw_nn_o_o_o_o, "auto_unroll_max_step", 1024)
    s[conv2d_nchw].pragma(conv2d_nchw_nn_o_o_o_o, "unroll_explicit", True)

    CUDA source code:

    #ifdef _WIN32
      using uint = unsigned int;
      using uchar = unsigned char;
      using ushort = unsigned short;
      using int64_t = long long;
      using uint64_t = unsigned long long;
    #else
      #define uint unsigned int
      #define uchar unsigned char
      #define ushort unsigned short
      #define int64_t long long
      #define uint64_t unsigned long long
    #endif
    extern "C" __global__ void __launch_bounds__(112) default_function_kernel0(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute, float* __restrict__ bias) {
      float conv2d_nchw[8];
      __shared__ float pad_temp_shared[54];
      __shared__ float kernel_shared[2304];
      conv2d_nchw[0] = 0.000000e+00f;
      conv2d_nchw[2] = 0.000000e+00f;
      conv2d_nchw[4] = 0.000000e+00f;
      conv2d_nchw[6] = 0.000000e+00f;
      conv2d_nchw[1] = 0.000000e+00f;
      conv2d_nchw[3] = 0.000000e+00f;
      conv2d_nchw[5] = 0.000000e+00f;
      conv2d_nchw[7] = 0.000000e+00f;
      for (int rc_outer_outer = 0; rc_outer_outer < 256; ++rc_outer_outer) {
        __syncthreads();
        if (((int)threadIdx.x) < 54) {
          pad_temp_shared[((int)threadIdx.x)] = (((((3 <= (((int)threadIdx.x) % 27)) && ((((int)threadIdx.x) % 27) < 24)) && (1 <= ((((int)blockIdx.x) % 7) + (((int)threadIdx.x) % 3)))) && (((((int)blockIdx.x) % 7) + (((int)threadIdx.x) % 3)) < 8)) ? data[((((((rc_outer_outer * 98) + ((((int)threadIdx.x) / 27) * 49)) + (((((int)threadIdx.x) % 27) / 3) * 7)) + (((int)blockIdx.x) % 7)) + (((int)threadIdx.x) % 3)) - 8)] : 0.000000e+00f);
        }
        kernel_shared[((int)threadIdx.x)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + ((((int)threadIdx.x) / 18) * 4608)) + (rc_outer_outer * 18)) + (((int)threadIdx.x) % 18))];
        kernel_shared[(((int)threadIdx.x) + 112)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 112) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 4) % 18))];
        kernel_shared[(((int)threadIdx.x) + 224)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 224) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 8) % 18))];
        kernel_shared[(((int)threadIdx.x) + 336)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 336) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 12) % 18))];
        kernel_shared[(((int)threadIdx.x) + 448)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 448) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 16) % 18))];
        kernel_shared[(((int)threadIdx.x) + 560)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 560) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 2) % 18))];
        kernel_shared[(((int)threadIdx.x) + 672)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 672) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 6) % 18))];
        kernel_shared[(((int)threadIdx.x) + 784)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 784) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 10) % 18))];
        kernel_shared[(((int)threadIdx.x) + 896)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 896) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 14) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1008)] = kernel[((((((((int)blockIdx.x) / 7) * 589824) + ((((int)threadIdx.x) / 18) * 4608)) + (rc_outer_outer * 18)) + (((int)threadIdx.x) % 18)) + 258048)];
        kernel_shared[(((int)threadIdx.x) + 1120)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1120) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 4) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1232)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1232) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 8) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1344)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1344) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 12) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1456)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1456) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 16) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1568)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1568) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 2) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1680)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1680) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 6) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1792)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1792) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 10) % 18))];
        kernel_shared[(((int)threadIdx.x) + 1904)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 1904) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 14) % 18))];
        kernel_shared[(((int)threadIdx.x) + 2016)] = kernel[((((((((int)blockIdx.x) / 7) * 589824) + ((((int)threadIdx.x) / 18) * 4608)) + (rc_outer_outer * 18)) + (((int)threadIdx.x) % 18)) + 516096)];
        kernel_shared[(((int)threadIdx.x) + 2128)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 2128) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 4) % 18))];
        if (((int)threadIdx.x) < 64) {
          kernel_shared[(((int)threadIdx.x) + 2240)] = kernel[(((((((int)blockIdx.x) / 7) * 589824) + (((((int)threadIdx.x) + 2240) / 18) * 4608)) + (rc_outer_outer * 18)) + ((((int)threadIdx.x) + 8) % 18))];
        }
        __syncthreads();
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[((((int)threadIdx.x) / 7) * 36)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 576)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1152)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1728)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 18)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 594)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1170)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((int)threadIdx.x) % 7) * 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1746)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 577)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1153)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1729)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 19)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 595)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1171)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 1)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1747)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 2)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 578)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1154)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1730)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 20)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 596)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1172)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 2)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1748)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 3)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 579)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1155)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1731)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 21)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 597)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1173)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 3)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1749)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 4)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 580)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1156)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1732)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 22)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 598)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1174)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 4)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1750)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 5)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 581)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1157)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1733)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 23)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 599)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1175)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 5)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1751)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 6)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 582)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1158)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1734)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 24)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 600)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1176)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 6)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1752)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 7)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 583)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1159)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1735)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 25)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 601)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1177)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 7)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1753)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 8)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 584)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1160)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1736)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 26)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 602)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1178)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 8)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1754)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 9)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 585)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1161)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1737)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 27)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 603)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1179)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 27)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1755)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 10)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 586)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1162)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1738)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 28)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 604)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1180)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 28)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1756)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 11)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 587)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1163)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1739)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 29)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 605)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1181)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 29)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1757)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 12)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 588)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1164)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1740)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 30)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 606)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1182)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 30)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1758)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 13)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 589)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1165)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1741)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 31)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 607)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1183)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 31)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1759)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 14)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 590)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1166)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1742)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 32)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 608)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1184)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 32)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1760)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 15)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 591)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1167)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1743)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 33)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 609)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1185)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 33)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1761)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 16)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 592)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1168)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1744)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 34)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 610)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1186)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 34)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1762)]));
        conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 17)]));
        conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 593)]));
        conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1169)]));
        conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1745)]));
        conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 35)]));
        conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 611)]));
        conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1187)]));
        conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 3) + 35)] * kernel_shared[(((((int)threadIdx.x) / 7) * 36) + 1763)]));
      }
      for (int i1_inner = 0; i1_inner < 2; ++i1_inner) {
        compute[((((((((int)blockIdx.x) / 7) * 6272) + ((((int)threadIdx.x) / 7) * 98)) + (i1_inner * 49)) + ((((int)threadIdx.x) % 7) * 7)) + (((int)blockIdx.x) % 7))] = max((conv2d_nchw[i1_inner] + bias[((((((int)blockIdx.x) / 7) * 128) + ((((int)threadIdx.x) / 7) * 2)) + i1_inner)]), 0.000000e+00f);
        compute[(((((((((int)blockIdx.x) / 7) * 6272) + ((((int)threadIdx.x) / 7) * 98)) + (i1_inner * 49)) + ((((int)threadIdx.x) % 7) * 7)) + (((int)blockIdx.x) % 7)) + 1568)] = max((conv2d_nchw[(i1_inner + 2)] + bias[(((((((int)blockIdx.x) / 7) * 128) + ((((int)threadIdx.x) / 7) * 2)) + i1_inner) + 32)]), 0.000000e+00f);
        compute[(((((((((int)blockIdx.x) / 7) * 6272) + ((((int)threadIdx.x) / 7) * 98)) + (i1_inner * 49)) + ((((int)threadIdx.x) % 7) * 7)) + (((int)blockIdx.x) % 7)) + 3136)] = max((conv2d_nchw[(i1_inner + 4)] + bias[(((((((int)blockIdx.x) / 7) * 128) + ((((int)threadIdx.x) / 7) * 2)) + i1_inner) + 64)]), 0.000000e+00f);
        compute[(((((((((int)blockIdx.x) / 7) * 6272) + ((((int)threadIdx.x) / 7) * 98)) + (i1_inner * 49)) + ((((int)threadIdx.x) % 7) * 7)) + (((int)blockIdx.x) % 7)) + 4704)] = max((conv2d_nchw[(i1_inner + 6)] + bias[(((((((int)blockIdx.x) / 7) * 128) + ((((int)threadIdx.x) / 7) * 2)) + i1_inner) + 96)]), 0.000000e+00f);
      }
    }





A more complicated example is to resume the search.
In this case, we need to create the search policy and cost model by ourselves
and resume the status of search policy and cost model with the log file.
In the example below we resume the status and do more 5 trials.


.. code-block:: default



    def resume_search(task, log_file):
        print("Resume search:")
        cost_model = auto_scheduler.XGBModel()
        cost_model.update_from_file(log_file)
        search_policy = auto_scheduler.SketchPolicy(
            task, cost_model, init_search_callbacks=[auto_scheduler.PreloadMeasuredStates(log_file)]
        )
        measure_ctx = auto_scheduler.LocalRPCMeasureContext(min_repeat_ms=300)
        tune_option = auto_scheduler.TuningOptions(
            num_measure_trials=5,
            runner=measure_ctx.runner,
            measure_callbacks=[auto_scheduler.RecordToFile(log_file)],
        )
        task.tune(tune_option, search_policy=search_policy)

        # Kill the measurement process
        del measure_ctx


    resume_search(task, log_file)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Resume search:
    /usr/local/lib/python3.6/dist-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
      warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
    Get devices for measurement successfully!





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  21.347 seconds)


.. _sphx_glr_download_how_to_tune_with_autoscheduler_tune_conv2d_layer_cuda.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: tune_conv2d_layer_cuda.py <tune_conv2d_layer_cuda.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: tune_conv2d_layer_cuda.ipynb <tune_conv2d_layer_cuda.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
