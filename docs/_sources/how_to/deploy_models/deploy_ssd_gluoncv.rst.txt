
.. DO NOT EDIT. THIS FILE WAS AUTOMATICALLY GENERATED BY
.. TVM'S MONKEY-PATCHED VERSION OF SPHINX-GALLERY. TO MAKE
.. CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "how_to/deploy_models/deploy_ssd_gluoncv.py"

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        This tutorial can be used interactively with Google Colab! You can also click
        :ref:`here <sphx_glr_download_how_to_deploy_models_deploy_ssd_gluoncv.py>` to run the Jupyter notebook locally.

        .. image:: https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg
            :align: center
            :target: https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/d92aacfae35477bed0f7f60aa8d2714e/deploy_ssd_gluoncv.ipynb
            :width: 300px

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_deploy_models_deploy_ssd_gluoncv.py:


Deploy Single Shot Multibox Detector(SSD) model
===============================================
**Author**: `Yao Wang <https://github.com/kevinthesun>`_
`Leyuan Wang <https://github.com/Laurawly>`_

This article is an introductory tutorial to deploy SSD models with TVM.
We will use GluonCV pre-trained SSD model and convert it to Relay IR

.. GENERATED FROM PYTHON SOURCE LINES 26-37

.. code-block:: default


    import tvm
    from tvm import te

    from matplotlib import pyplot as plt
    from tvm import relay
    from tvm.contrib import graph_executor
    from tvm.contrib.download import download_testdata
    from gluoncv import model_zoo, data, utils






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/gluoncv/check.py:8: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      if LooseVersion(mx.__version__) < LooseVersion(mx_version) or \
    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/gluoncv/check.py:9: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      LooseVersion(mx.__version__) >= LooseVersion(max_mx_version):
    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/gluoncv/check.py:30: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      if LooseVersion(torch.__version__) < LooseVersion(torch_version) or \
    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/gluoncv/check.py:31: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
      LooseVersion(torch.__version__) >= LooseVersion(max_torch_version):
    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.6.0` and `torch==1.12.0+cpu` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.
      warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '




.. GENERATED FROM PYTHON SOURCE LINES 38-60

Preliminary and Set parameters
------------------------------
.. note::

  We support compiling SSD on both CPUs and GPUs now.

  To get best inference performance on CPU, change
  target argument according to your device and
  follow the :ref:`tune_relay_x86` to tune x86 CPU and
  :ref:`tune_relay_arm` for arm CPU.

  To get best inference performance on Intel graphics,
  change target argument to :code:`opencl -device=intel_graphics`.
  But when using Intel graphics on Mac, target needs to
  be set to `opencl` only for the reason that Intel subgroup
  extension is not supported on Mac.

  To get best inference performance on CUDA-based GPUs,
  change the target argument to :code:`cuda`; and for
  OPENCL-based GPUs, change target argument to
  :code:`opencl` followed by device argument according
  to your device.

.. GENERATED FROM PYTHON SOURCE LINES 60-73

.. code-block:: default


    supported_model = [
        "ssd_512_resnet50_v1_voc",
        "ssd_512_resnet50_v1_coco",
        "ssd_512_resnet101_v2_voc",
        "ssd_512_mobilenet1.0_voc",
        "ssd_512_mobilenet1.0_coco",
        "ssd_300_vgg16_atrous_voc" "ssd_512_vgg16_atrous_coco",
    ]

    model_name = supported_model[0]
    dshape = (1, 3, 512, 512)








.. GENERATED FROM PYTHON SOURCE LINES 74-75

Download and pre-process demo image

.. GENERATED FROM PYTHON SOURCE LINES 75-83

.. code-block:: default


    im_fname = download_testdata(
        "https://github.com/dmlc/web-data/blob/main/" + "gluoncv/detection/street_small.jpg?raw=true",
        "street_small.jpg",
        module="data",
    )
    x, img = data.transforms.presets.ssd.load_test(im_fname, short=512)








.. GENERATED FROM PYTHON SOURCE LINES 84-85

Convert and compile model for CPU.

.. GENERATED FROM PYTHON SOURCE LINES 85-96

.. code-block:: default


    block = model_zoo.get_model(model_name, pretrained=True)


    def build(target):
        mod, params = relay.frontend.from_mxnet(block, {"data": dshape})
        with tvm.transform.PassContext(opt_level=3):
            lib = relay.build(mod, target, params=params)
        return lib






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /venv/apache-tvm-py3.7/lib/python3.7/site-packages/mxnet/gluon/block.py:1389: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
            data: None
      input_sym_arg_type = in_param.infer_type()[0]
    Downloading /workspace/.mxnet/models/ssd_512_resnet50_v1_voc-9c8b225a.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/ssd_512_resnet50_v1_voc-9c8b225a.zip...
      0%|          | 0/132723 [00:00<?, ?KB/s]      1%|          | 665/132723 [00:00<00:20, 6582.76KB/s]      1%|1         | 1756/132723 [00:00<00:14, 9090.43KB/s]      3%|2         | 3468/132723 [00:00<00:10, 12737.92KB/s]      5%|4         | 6220/132723 [00:00<00:06, 18491.87KB/s]      8%|7         | 10609/132723 [00:00<00:04, 27613.24KB/s]     13%|#3        | 17416/132723 [00:00<00:02, 41330.91KB/s]     19%|#9        | 25301/132723 [00:00<00:02, 53573.67KB/s]     25%|##5       | 33318/132723 [00:00<00:01, 62028.35KB/s]     31%|###1      | 41372/132723 [00:00<00:01, 67804.17KB/s]     37%|###7      | 49457/132723 [00:01<00:01, 71825.33KB/s]     43%|####3     | 57589/132723 [00:01<00:01, 74726.54KB/s]     49%|####9     | 65661/132723 [00:01<00:00, 76545.99KB/s]     56%|#####5    | 73740/132723 [00:01<00:00, 77829.39KB/s]     62%|######1   | 81818/132723 [00:01<00:00, 78717.72KB/s]     68%|######7   | 89952/132723 [00:01<00:00, 79505.30KB/s]     74%|#######3  | 98097/132723 [00:01<00:00, 80088.75KB/s]     80%|#######9  | 106168/132723 [00:01<00:00, 80273.60KB/s]     86%|########6 | 114243/132723 [00:01<00:00, 80414.46KB/s]     92%|#########2| 122352/132723 [00:01<00:00, 80615.11KB/s]     98%|#########8| 130460/132723 [00:02<00:00, 80751.58KB/s]    100%|##########| 132723/132723 [00:02<00:00, 65342.56KB/s]




.. GENERATED FROM PYTHON SOURCE LINES 97-102

Create TVM runtime and do inference
.. note::

  Use target = "cuda -libs" to enable thrust based sort, if you
  enabled thrust during cmake by -DUSE_THRUST=ON.

.. GENERATED FROM PYTHON SOURCE LINES 102-122

.. code-block:: default



    def run(lib, dev):
        # Build TVM runtime
        m = graph_executor.GraphModule(lib["default"](dev))
        tvm_input = tvm.nd.array(x.asnumpy(), device=dev)
        m.set_input("data", tvm_input)
        # execute
        m.run()
        # get outputs
        class_IDs, scores, bounding_boxs = m.get_output(0), m.get_output(1), m.get_output(2)
        return class_IDs, scores, bounding_boxs


    for target in ["llvm", "cuda"]:
        dev = tvm.device(target, 0)
        if dev.exist:
            lib = build(target)
            class_IDs, scores, bounding_boxs = run(lib, dev)








.. GENERATED FROM PYTHON SOURCE LINES 123-124

Display result

.. GENERATED FROM PYTHON SOURCE LINES 124-133

.. code-block:: default


    ax = utils.viz.plot_bbox(
        img,
        bounding_boxs.numpy()[0],
        scores.numpy()[0],
        class_IDs.numpy()[0],
        class_names=block.classes,
    )
    plt.show()



.. image-sg:: /how_to/deploy_models/images/sphx_glr_deploy_ssd_gluoncv_001.png
   :alt: deploy ssd gluoncv
   :srcset: /how_to/deploy_models/images/sphx_glr_deploy_ssd_gluoncv_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  51.536 seconds)


.. _sphx_glr_download_how_to_deploy_models_deploy_ssd_gluoncv.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: deploy_ssd_gluoncv.py <deploy_ssd_gluoncv.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: deploy_ssd_gluoncv.ipynb <deploy_ssd_gluoncv.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
