:orphan:

Deploy Deep Learning Models
---------------------------

TVM is capable of deploying models to a variety of different platforms. These
how-tos describe how to prepapre and deploy models to many of the supported
backends.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This article is a step-by-step tutorial to deploy pretrained Pytorch ResNet-18 model on Adreno (on different precisions).">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_model_on_adreno_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_model_on_adreno.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy the Pretrained Model on Adreno™</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This article is a step-by-step tutorial to deploy pretrained PyTorch resnet50 model on Adreno™.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_model_on_adreno_tvmc_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_model_on_adreno_tvmc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy the Pretrained Model on Adreno™ with tvmc Interface</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example of using Relay to compile a keras model and deploy it on Android device.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_model_on_android_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_model_on_android.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy the Pretrained Model on Android</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example of using Relay to compile a ResNet model and deploy it on Jetson Nano.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_model_on_nano_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_model_on_nano.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy the Pretrained Model on Jetson Nano</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example of using Relay to compile a ResNet model and deploy it on Raspberry Pi.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_model_on_rasp_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_model_on_rasp.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy the Pretrained Model on Raspberry Pi</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="For us to begin with, PyTorch should be installed. TorchVision is also required since we will be using it as our model zoo.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_object_detection_pytorch_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_object_detection_pytorch.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compile PyTorch Object Detection Models</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is a tutorial on loading models quantized by deep learning frameworks into TVM. Pre-quantized model import is one of the quantization support we have in TVM. More details on the quantization story in TVM can be found here.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_prequantized_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_prequantized.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy a Framework-prequantized Model with TVM</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Welcome to part 3 of the Deploy Framework-Prequantized Model with TVM tutorial. In this part, we will start with a Quantized TFLite graph and then compile and execute it via TVM.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_prequantized_tflite_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_prequantized_tflite.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy a Framework-prequantized Model with TVM - Part 3 (TFLite)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This tutorial demonstrates how to take any pruned model, in this case PruneBert from Hugging Face, and use TVM to leverage the model&#x27;s sparsity support to produce real speedups. Although the primary purpose of this tutorial is to realize speedups on already pruned models, it may also be useful to estimate how fast a model would be if it were pruned. To this end, we also provide a function that takes an unpruned model and replaces its weights with random and pruned weights at a specified sparsity. This may be a useful feature when trying to decide if a model is worth pruning or not.">

.. only:: html

  .. image:: /how_to/deploy_models/images/thumb/sphx_glr_deploy_sparse_thumb.png
    :alt:

  :ref:`sphx_glr_how_to_deploy_models_deploy_sparse.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deploy a Hugging Face Pruned Model on CPU</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /how_to/deploy_models/deploy_model_on_adreno
   /how_to/deploy_models/deploy_model_on_adreno_tvmc
   /how_to/deploy_models/deploy_model_on_android
   /how_to/deploy_models/deploy_model_on_nano
   /how_to/deploy_models/deploy_model_on_rasp
   /how_to/deploy_models/deploy_object_detection_pytorch
   /how_to/deploy_models/deploy_prequantized
   /how_to/deploy_models/deploy_prequantized_tflite
   /how_to/deploy_models/deploy_sparse



.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
