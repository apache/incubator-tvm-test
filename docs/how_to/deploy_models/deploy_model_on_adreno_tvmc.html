



<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy the Pretrained Model on Adreno™ with tvmc Interface &mdash; tvm 0.19.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=95e146bd"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Deploy the Pretrained Model on Android" href="deploy_model_on_android.html" />
    <link rel="prev" title="Deploy the Pretrained Model on Adreno™" href="deploy_model_on_adreno.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://tvm.apache.org/docs/reference/security.html>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="sidetitle" alt="Documentation Home"> tvm
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/tutorials/ir_module.html">IRModule</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How To</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/e2e_opt_model.html">End-to-End Optimize Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/customize_opt.html">Customize Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/optimize_llm.html">Optimize Large Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">Development Guides</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/tensor_ir/index.html">TensorIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive/relax/index.html">Relax</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Legacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../legacy_index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#build-the-tvm-runtime-library">Build the TVM runtime library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#cross-compile-the-tvm-runtime-for-other-architectures">Cross compile the TVM runtime for other architectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#optimize-and-tune-models-for-target-devices">Optimize and tune models for target devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deploy/index.html#deploy-optimized-model-on-target-devices">Deploy optimized model on target devices</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../deploy/index.html#additional-deployment-how-tos">Additional Deployment How-Tos</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="index.html">Deploy Deep Learning Models</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autoscheduler/index.html">Use AutoScheduler for Template-Free Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_microtvm/index.html">Work With microTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/security.html">Security Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../legacy_index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="../deploy/index.html">Deploy Models and Integrate TVM</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Deploy Deep Learning Models</a> <span class="br-arrow">></span></li>
        
      <li>Deploy the Pretrained Model on Adreno™ with tvmc Interface</li>
    
    
      
      
        
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/tvm/edit/main/docs/how_to/deploy_models/deploy_model_on_adreno_tvmc.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial can be used interactively with Google Colab! You can also click
<a class="reference internal" href="#sphx-glr-download-how-to-deploy-models-deploy-model-on-adreno-tvmc-py"><span class="std std-ref">here</span></a> to run the Jupyter notebook locally.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/apache/tvm-site/blob/asf-site/docs/_downloads/613e0775d8981e544e6ca9602a975916/deploy_model_on_adreno_tvmc.ipynb"><img alt="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" class="align-center" src="https://raw.githubusercontent.com/tlc-pack/web-data/main/images/utilities/colab_button.svg" style="width: 300px;" />
</a>
</div>
<section class="sphx-glr-example-title" id="deploy-the-pretrained-model-on-adreno-with-tvmc-interface">
<span id="tutorial-deploy-model-on-adreno-tvmc"></span><span id="sphx-glr-how-to-deploy-models-deploy-model-on-adreno-tvmc-py"></span><h1>Deploy the Pretrained Model on Adreno™ with tvmc Interface<a class="headerlink" href="#deploy-the-pretrained-model-on-adreno-with-tvmc-interface" title="Link to this heading"></a></h1>
<p><strong>Author</strong>: Siva Rama Krishna</p>
<p>This article is a step-by-step tutorial to deploy pretrained PyTorch resnet50 model on Adreno™.</p>
<p>Besides that, you should have TVM built for Android.
See the following instructions on how to build it and setup RPC environment.</p>
<p><a class="reference external" href="https://tvm.apache.org/docs/how_to/deploy/adreno.html">Deploy to Adreno GPU</a></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.driver</span> <span class="kn">import</span> <span class="n">tvmc</span>
<span class="kn">from</span> <span class="nn">tvm.driver.tvmc.model</span> <span class="kn">import</span> <span class="n">TVMCPackage</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">utils</span>
</pre></div>
</div>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Link to this heading"></a></h2>
<p>Specify Adreno target before compiling to generate texture
leveraging kernels and get all the benefits of textures
Note: This generated example running on our x86 server for demonstration.
If running it on the Android device, we need to
specify its instruction set. Set <code class="code docutils literal notranslate"><span class="pre">local_demo</span></code> to False if you want
to run this tutorial with a real device over rpc.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># by default on CPU target will execute.</span>
<span class="c1"># select &#39;llvm&#39;, &#39;opencl&#39; and &#39;opencl -device=adreno&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <span class="s2">&quot;llvm&quot;</span>

<span class="c1"># Change target configuration.</span>
<span class="c1"># Run `adb shell cat /proc/cpuinfo` to find the arch.</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">arch</span></a> <span class="o">=</span> <span class="s2">&quot;arm64&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a> <span class="o">=</span> <span class="s2">&quot;llvm -mtriple=</span><span class="si">%s</span><span class="s2">-linux-android&quot;</span> <span class="o">%</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">arch</span></a>

<span class="c1"># Auto tuning is compute and time taking task, hence disabling for default run. Please enable it if required.</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">is_tuning</span></a> <span class="o">=</span> <span class="kc">False</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_log</span></a> <span class="o">=</span> <span class="s2">&quot;adreno-resnet50.log&quot;</span>

<span class="c1"># To enable OpenCLML accelerated operator library.</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">enable_clml</span></a> <span class="o">=</span> <span class="kc">False</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cross_compiler</span></a> <span class="o">=</span> <span class="p">(</span>
    <a href="https://docs.python.org/3/library/os.html#os.getenv" title="os.getenv" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">getenv</span></a><span class="p">(</span><span class="s2">&quot;ANDROID_NDK_HOME&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="s2">&quot;/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android28-clang&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="make-a-pytorch-resnet50-model">
<h2>Make a PyTorch Resnet50 Model<a class="headerlink" href="#make-a-pytorch-resnet50-model" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>

<span class="c1"># Load the ResNet50 model pre-trained on ImageNet</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set the model to evaluation mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Define the input shape</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="c1"># Trace the model</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">)</span>

<span class="c1"># Save the traced model</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_file_name</span></a> <span class="o">=</span> <span class="s2">&quot;resnet50_traced.pt&quot;</span>
<span class="n">traced_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_file_name</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/venv/apache-tvm-py3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and may be removed in the future, please use &#39;weights&#39; instead.
  warnings.warn(
/venv/apache-tvm-py3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: &quot;https://download.pytorch.org/models/resnet50-0676ba61.pth&quot; to /workspace/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth

  0%|          | 0.00/97.8M [00:00&lt;?, ?B/s]
 17%|█▋        | 16.2M/97.8M [00:00&lt;00:00, 170MB/s]
 40%|███▉      | 38.6M/97.8M [00:00&lt;00:00, 208MB/s]
 62%|██████▏   | 61.0M/97.8M [00:00&lt;00:00, 219MB/s]
 85%|████████▌ | 83.4M/97.8M [00:00&lt;00:00, 225MB/s]
100%|██████████| 97.8M/97.8M [00:00&lt;00:00, 220MB/s]
</pre></div>
</div>
</section>
<section id="load-model">
<h2>Load Model<a class="headerlink" href="#load-model" title="Link to this heading"></a></h2>
<p>Convert a model from any framework to a tvm relay module.
tvmc.load supports models from any framework (like tensorflow saves_model, onnx, tflite ..etc) and auto detects the filetype.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>  <span class="c1"># Batch size, channels, height, width</span>

<span class="c1"># Load the TorchScript model with TVMC</span>
<span class="n">tvmc_model</span> <span class="o">=</span> <span class="n">tvmc</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_file_name</span></a><span class="p">,</span> <span class="n">shape_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">input_shape</span></a><span class="p">},</span> <span class="n">model_format</span><span class="o">=</span><span class="s2">&quot;pytorch&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tvmc_model</span><span class="o">.</span><span class="n">mod</span><span class="p">)</span>

<span class="c1"># tvmc_model consists of tvmc_mode.mod which is relay module and tvmc_model.params which parms of the module.</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @main(%input: Tensor[(1, 3, 224, 224), float32] /* span=aten::_convolution_0.input:0:0 */, %aten::_convolution_0.weight: Tensor[(64, 3, 7, 7), float32] /* span=aten::_convolution_0.weight:0:0 */, %aten::batch_norm_0.weight: Tensor[(64), float32] /* span=aten::batch_norm_0.weight:0:0 */, %aten::batch_norm_0.bias: Tensor[(64), float32] /* span=aten::batch_norm_0.bias:0:0 */, %aten::batch_norm_0.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_0.running_mean:0:0 */, %aten::batch_norm_0.running_var: Tensor[(64), float32] /* span=aten::batch_norm_0.running_var:0:0 */, %aten::_convolution_1.weight: Tensor[(64, 64, 1, 1), float32] /* span=aten::_convolution_1.weight:0:0 */, %aten::batch_norm_1.weight: Tensor[(64), float32] /* span=aten::batch_norm_1.weight:0:0 */, %aten::batch_norm_1.bias: Tensor[(64), float32] /* span=aten::batch_norm_1.bias:0:0 */, %aten::batch_norm_1.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_1.running_mean:0:0 */, %aten::batch_norm_1.running_var: Tensor[(64), float32] /* span=aten::batch_norm_1.running_var:0:0 */, %aten::_convolution_2.weight: Tensor[(64, 64, 3, 3), float32] /* span=aten::_convolution_2.weight:0:0 */, %aten::batch_norm_2.weight: Tensor[(64), float32] /* span=aten::batch_norm_2.weight:0:0 */, %aten::batch_norm_2.bias: Tensor[(64), float32] /* span=aten::batch_norm_2.bias:0:0 */, %aten::batch_norm_2.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_2.running_mean:0:0 */, %aten::batch_norm_2.running_var: Tensor[(64), float32] /* span=aten::batch_norm_2.running_var:0:0 */, %aten::_convolution_3.weight: Tensor[(256, 64, 1, 1), float32] /* span=aten::_convolution_3.weight:0:0 */, %aten::batch_norm_3.weight: Tensor[(256), float32] /* span=aten::batch_norm_3.weight:0:0 */, %aten::batch_norm_3.bias: Tensor[(256), float32] /* span=aten::batch_norm_3.bias:0:0 */, %aten::batch_norm_3.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_3.running_mean:0:0 */, %aten::batch_norm_3.running_var: Tensor[(256), float32] /* span=aten::batch_norm_3.running_var:0:0 */, %aten::_convolution_4.weight: Tensor[(256, 64, 1, 1), float32] /* span=aten::_convolution_4.weight:0:0 */, %aten::batch_norm_4.weight: Tensor[(256), float32] /* span=aten::batch_norm_4.weight:0:0 */, %aten::batch_norm_4.bias: Tensor[(256), float32] /* span=aten::batch_norm_4.bias:0:0 */, %aten::batch_norm_4.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_4.running_mean:0:0 */, %aten::batch_norm_4.running_var: Tensor[(256), float32] /* span=aten::batch_norm_4.running_var:0:0 */, %aten::_convolution_5.weight: Tensor[(64, 256, 1, 1), float32] /* span=aten::_convolution_5.weight:0:0 */, %aten::batch_norm_5.weight: Tensor[(64), float32] /* span=aten::batch_norm_5.weight:0:0 */, %aten::batch_norm_5.bias: Tensor[(64), float32] /* span=aten::batch_norm_5.bias:0:0 */, %aten::batch_norm_5.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_5.running_mean:0:0 */, %aten::batch_norm_5.running_var: Tensor[(64), float32] /* span=aten::batch_norm_5.running_var:0:0 */, %aten::_convolution_6.weight: Tensor[(64, 64, 3, 3), float32] /* span=aten::_convolution_6.weight:0:0 */, %aten::batch_norm_6.weight: Tensor[(64), float32] /* span=aten::batch_norm_6.weight:0:0 */, %aten::batch_norm_6.bias: Tensor[(64), float32] /* span=aten::batch_norm_6.bias:0:0 */, %aten::batch_norm_6.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_6.running_mean:0:0 */, %aten::batch_norm_6.running_var: Tensor[(64), float32] /* span=aten::batch_norm_6.running_var:0:0 */, %aten::_convolution_7.weight: Tensor[(256, 64, 1, 1), float32] /* span=aten::_convolution_7.weight:0:0 */, %aten::batch_norm_7.weight: Tensor[(256), float32] /* span=aten::batch_norm_7.weight:0:0 */, %aten::batch_norm_7.bias: Tensor[(256), float32] /* span=aten::batch_norm_7.bias:0:0 */, %aten::batch_norm_7.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_7.running_mean:0:0 */, %aten::batch_norm_7.running_var: Tensor[(256), float32] /* span=aten::batch_norm_7.running_var:0:0 */, %aten::_convolution_8.weight: Tensor[(64, 256, 1, 1), float32] /* span=aten::_convolution_8.weight:0:0 */, %aten::batch_norm_8.weight: Tensor[(64), float32] /* span=aten::batch_norm_8.weight:0:0 */, %aten::batch_norm_8.bias: Tensor[(64), float32] /* span=aten::batch_norm_8.bias:0:0 */, %aten::batch_norm_8.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_8.running_mean:0:0 */, %aten::batch_norm_8.running_var: Tensor[(64), float32] /* span=aten::batch_norm_8.running_var:0:0 */, %aten::_convolution_9.weight: Tensor[(64, 64, 3, 3), float32] /* span=aten::_convolution_9.weight:0:0 */, %aten::batch_norm_9.weight: Tensor[(64), float32] /* span=aten::batch_norm_9.weight:0:0 */, %aten::batch_norm_9.bias: Tensor[(64), float32] /* span=aten::batch_norm_9.bias:0:0 */, %aten::batch_norm_9.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_9.running_mean:0:0 */, %aten::batch_norm_9.running_var: Tensor[(64), float32] /* span=aten::batch_norm_9.running_var:0:0 */, %aten::_convolution_10.weight: Tensor[(256, 64, 1, 1), float32] /* span=aten::_convolution_10.weight:0:0 */, %aten::batch_norm_10.weight: Tensor[(256), float32] /* span=aten::batch_norm_10.weight:0:0 */, %aten::batch_norm_10.bias: Tensor[(256), float32] /* span=aten::batch_norm_10.bias:0:0 */, %aten::batch_norm_10.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_10.running_mean:0:0 */, %aten::batch_norm_10.running_var: Tensor[(256), float32] /* span=aten::batch_norm_10.running_var:0:0 */, %aten::_convolution_11.weight: Tensor[(128, 256, 1, 1), float32] /* span=aten::_convolution_11.weight:0:0 */, %aten::batch_norm_11.weight: Tensor[(128), float32] /* span=aten::batch_norm_11.weight:0:0 */, %aten::batch_norm_11.bias: Tensor[(128), float32] /* span=aten::batch_norm_11.bias:0:0 */, %aten::batch_norm_11.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_11.running_mean:0:0 */, %aten::batch_norm_11.running_var: Tensor[(128), float32] /* span=aten::batch_norm_11.running_var:0:0 */, %aten::_convolution_12.weight: Tensor[(128, 128, 3, 3), float32] /* span=aten::_convolution_12.weight:0:0 */, %aten::batch_norm_12.weight: Tensor[(128), float32] /* span=aten::batch_norm_12.weight:0:0 */, %aten::batch_norm_12.bias: Tensor[(128), float32] /* span=aten::batch_norm_12.bias:0:0 */, %aten::batch_norm_12.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_12.running_mean:0:0 */, %aten::batch_norm_12.running_var: Tensor[(128), float32] /* span=aten::batch_norm_12.running_var:0:0 */, %aten::_convolution_13.weight: Tensor[(512, 128, 1, 1), float32] /* span=aten::_convolution_13.weight:0:0 */, %aten::batch_norm_13.weight: Tensor[(512), float32] /* span=aten::batch_norm_13.weight:0:0 */, %aten::batch_norm_13.bias: Tensor[(512), float32] /* span=aten::batch_norm_13.bias:0:0 */, %aten::batch_norm_13.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_13.running_mean:0:0 */, %aten::batch_norm_13.running_var: Tensor[(512), float32] /* span=aten::batch_norm_13.running_var:0:0 */, %aten::_convolution_14.weight: Tensor[(512, 256, 1, 1), float32] /* span=aten::_convolution_14.weight:0:0 */, %aten::batch_norm_14.weight: Tensor[(512), float32] /* span=aten::batch_norm_14.weight:0:0 */, %aten::batch_norm_14.bias: Tensor[(512), float32] /* span=aten::batch_norm_14.bias:0:0 */, %aten::batch_norm_14.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_14.running_mean:0:0 */, %aten::batch_norm_14.running_var: Tensor[(512), float32] /* span=aten::batch_norm_14.running_var:0:0 */, %aten::_convolution_15.weight: Tensor[(128, 512, 1, 1), float32] /* span=aten::_convolution_15.weight:0:0 */, %aten::batch_norm_15.weight: Tensor[(128), float32] /* span=aten::batch_norm_15.weight:0:0 */, %aten::batch_norm_15.bias: Tensor[(128), float32] /* span=aten::batch_norm_15.bias:0:0 */, %aten::batch_norm_15.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_15.running_mean:0:0 */, %aten::batch_norm_15.running_var: Tensor[(128), float32] /* span=aten::batch_norm_15.running_var:0:0 */, %aten::_convolution_16.weight: Tensor[(128, 128, 3, 3), float32] /* span=aten::_convolution_16.weight:0:0 */, %aten::batch_norm_16.weight: Tensor[(128), float32] /* span=aten::batch_norm_16.weight:0:0 */, %aten::batch_norm_16.bias: Tensor[(128), float32] /* span=aten::batch_norm_16.bias:0:0 */, %aten::batch_norm_16.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_16.running_mean:0:0 */, %aten::batch_norm_16.running_var: Tensor[(128), float32] /* span=aten::batch_norm_16.running_var:0:0 */, %aten::_convolution_17.weight: Tensor[(512, 128, 1, 1), float32] /* span=aten::_convolution_17.weight:0:0 */, %aten::batch_norm_17.weight: Tensor[(512), float32] /* span=aten::batch_norm_17.weight:0:0 */, %aten::batch_norm_17.bias: Tensor[(512), float32] /* span=aten::batch_norm_17.bias:0:0 */, %aten::batch_norm_17.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_17.running_mean:0:0 */, %aten::batch_norm_17.running_var: Tensor[(512), float32] /* span=aten::batch_norm_17.running_var:0:0 */, %aten::_convolution_18.weight: Tensor[(128, 512, 1, 1), float32] /* span=aten::_convolution_18.weight:0:0 */, %aten::batch_norm_18.weight: Tensor[(128), float32] /* span=aten::batch_norm_18.weight:0:0 */, %aten::batch_norm_18.bias: Tensor[(128), float32] /* span=aten::batch_norm_18.bias:0:0 */, %aten::batch_norm_18.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_18.running_mean:0:0 */, %aten::batch_norm_18.running_var: Tensor[(128), float32] /* span=aten::batch_norm_18.running_var:0:0 */, %aten::_convolution_19.weight: Tensor[(128, 128, 3, 3), float32] /* span=aten::_convolution_19.weight:0:0 */, %aten::batch_norm_19.weight: Tensor[(128), float32] /* span=aten::batch_norm_19.weight:0:0 */, %aten::batch_norm_19.bias: Tensor[(128), float32] /* span=aten::batch_norm_19.bias:0:0 */, %aten::batch_norm_19.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_19.running_mean:0:0 */, %aten::batch_norm_19.running_var: Tensor[(128), float32] /* span=aten::batch_norm_19.running_var:0:0 */, %aten::_convolution_20.weight: Tensor[(512, 128, 1, 1), float32] /* span=aten::_convolution_20.weight:0:0 */, %aten::batch_norm_20.weight: Tensor[(512), float32] /* span=aten::batch_norm_20.weight:0:0 */, %aten::batch_norm_20.bias: Tensor[(512), float32] /* span=aten::batch_norm_20.bias:0:0 */, %aten::batch_norm_20.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_20.running_mean:0:0 */, %aten::batch_norm_20.running_var: Tensor[(512), float32] /* span=aten::batch_norm_20.running_var:0:0 */, %aten::_convolution_21.weight: Tensor[(128, 512, 1, 1), float32] /* span=aten::_convolution_21.weight:0:0 */, %aten::batch_norm_21.weight: Tensor[(128), float32] /* span=aten::batch_norm_21.weight:0:0 */, %aten::batch_norm_21.bias: Tensor[(128), float32] /* span=aten::batch_norm_21.bias:0:0 */, %aten::batch_norm_21.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_21.running_mean:0:0 */, %aten::batch_norm_21.running_var: Tensor[(128), float32] /* span=aten::batch_norm_21.running_var:0:0 */, %aten::_convolution_22.weight: Tensor[(128, 128, 3, 3), float32] /* span=aten::_convolution_22.weight:0:0 */, %aten::batch_norm_22.weight: Tensor[(128), float32] /* span=aten::batch_norm_22.weight:0:0 */, %aten::batch_norm_22.bias: Tensor[(128), float32] /* span=aten::batch_norm_22.bias:0:0 */, %aten::batch_norm_22.running_mean: Tensor[(128), float32] /* span=aten::batch_norm_22.running_mean:0:0 */, %aten::batch_norm_22.running_var: Tensor[(128), float32] /* span=aten::batch_norm_22.running_var:0:0 */, %aten::_convolution_23.weight: Tensor[(512, 128, 1, 1), float32] /* span=aten::_convolution_23.weight:0:0 */, %aten::batch_norm_23.weight: Tensor[(512), float32] /* span=aten::batch_norm_23.weight:0:0 */, %aten::batch_norm_23.bias: Tensor[(512), float32] /* span=aten::batch_norm_23.bias:0:0 */, %aten::batch_norm_23.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_23.running_mean:0:0 */, %aten::batch_norm_23.running_var: Tensor[(512), float32] /* span=aten::batch_norm_23.running_var:0:0 */, %aten::_convolution_24.weight: Tensor[(256, 512, 1, 1), float32] /* span=aten::_convolution_24.weight:0:0 */, %aten::batch_norm_24.weight: Tensor[(256), float32] /* span=aten::batch_norm_24.weight:0:0 */, %aten::batch_norm_24.bias: Tensor[(256), float32] /* span=aten::batch_norm_24.bias:0:0 */, %aten::batch_norm_24.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_24.running_mean:0:0 */, %aten::batch_norm_24.running_var: Tensor[(256), float32] /* span=aten::batch_norm_24.running_var:0:0 */, %aten::_convolution_25.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_25.weight:0:0 */, %aten::batch_norm_25.weight: Tensor[(256), float32] /* span=aten::batch_norm_25.weight:0:0 */, %aten::batch_norm_25.bias: Tensor[(256), float32] /* span=aten::batch_norm_25.bias:0:0 */, %aten::batch_norm_25.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_25.running_mean:0:0 */, %aten::batch_norm_25.running_var: Tensor[(256), float32] /* span=aten::batch_norm_25.running_var:0:0 */, %aten::_convolution_26.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_26.weight:0:0 */, %aten::batch_norm_26.weight: Tensor[(1024), float32] /* span=aten::batch_norm_26.weight:0:0 */, %aten::batch_norm_26.bias: Tensor[(1024), float32] /* span=aten::batch_norm_26.bias:0:0 */, %aten::batch_norm_26.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_26.running_mean:0:0 */, %aten::batch_norm_26.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_26.running_var:0:0 */, %aten::_convolution_27.weight: Tensor[(1024, 512, 1, 1), float32] /* span=aten::_convolution_27.weight:0:0 */, %aten::batch_norm_27.weight: Tensor[(1024), float32] /* span=aten::batch_norm_27.weight:0:0 */, %aten::batch_norm_27.bias: Tensor[(1024), float32] /* span=aten::batch_norm_27.bias:0:0 */, %aten::batch_norm_27.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_27.running_mean:0:0 */, %aten::batch_norm_27.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_27.running_var:0:0 */, %aten::_convolution_28.weight: Tensor[(256, 1024, 1, 1), float32] /* span=aten::_convolution_28.weight:0:0 */, %aten::batch_norm_28.weight: Tensor[(256), float32] /* span=aten::batch_norm_28.weight:0:0 */, %aten::batch_norm_28.bias: Tensor[(256), float32] /* span=aten::batch_norm_28.bias:0:0 */, %aten::batch_norm_28.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_28.running_mean:0:0 */, %aten::batch_norm_28.running_var: Tensor[(256), float32] /* span=aten::batch_norm_28.running_var:0:0 */, %aten::_convolution_29.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_29.weight:0:0 */, %aten::batch_norm_29.weight: Tensor[(256), float32] /* span=aten::batch_norm_29.weight:0:0 */, %aten::batch_norm_29.bias: Tensor[(256), float32] /* span=aten::batch_norm_29.bias:0:0 */, %aten::batch_norm_29.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_29.running_mean:0:0 */, %aten::batch_norm_29.running_var: Tensor[(256), float32] /* span=aten::batch_norm_29.running_var:0:0 */, %aten::_convolution_30.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_30.weight:0:0 */, %aten::batch_norm_30.weight: Tensor[(1024), float32] /* span=aten::batch_norm_30.weight:0:0 */, %aten::batch_norm_30.bias: Tensor[(1024), float32] /* span=aten::batch_norm_30.bias:0:0 */, %aten::batch_norm_30.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_30.running_mean:0:0 */, %aten::batch_norm_30.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_30.running_var:0:0 */, %aten::_convolution_31.weight: Tensor[(256, 1024, 1, 1), float32] /* span=aten::_convolution_31.weight:0:0 */, %aten::batch_norm_31.weight: Tensor[(256), float32] /* span=aten::batch_norm_31.weight:0:0 */, %aten::batch_norm_31.bias: Tensor[(256), float32] /* span=aten::batch_norm_31.bias:0:0 */, %aten::batch_norm_31.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_31.running_mean:0:0 */, %aten::batch_norm_31.running_var: Tensor[(256), float32] /* span=aten::batch_norm_31.running_var:0:0 */, %aten::_convolution_32.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_32.weight:0:0 */, %aten::batch_norm_32.weight: Tensor[(256), float32] /* span=aten::batch_norm_32.weight:0:0 */, %aten::batch_norm_32.bias: Tensor[(256), float32] /* span=aten::batch_norm_32.bias:0:0 */, %aten::batch_norm_32.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_32.running_mean:0:0 */, %aten::batch_norm_32.running_var: Tensor[(256), float32] /* span=aten::batch_norm_32.running_var:0:0 */, %aten::_convolution_33.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_33.weight:0:0 */, %aten::batch_norm_33.weight: Tensor[(1024), float32] /* span=aten::batch_norm_33.weight:0:0 */, %aten::batch_norm_33.bias: Tensor[(1024), float32] /* span=aten::batch_norm_33.bias:0:0 */, %aten::batch_norm_33.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_33.running_mean:0:0 */, %aten::batch_norm_33.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_33.running_var:0:0 */, %aten::_convolution_34.weight: Tensor[(256, 1024, 1, 1), float32] /* span=aten::_convolution_34.weight:0:0 */, %aten::batch_norm_34.weight: Tensor[(256), float32] /* span=aten::batch_norm_34.weight:0:0 */, %aten::batch_norm_34.bias: Tensor[(256), float32] /* span=aten::batch_norm_34.bias:0:0 */, %aten::batch_norm_34.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_34.running_mean:0:0 */, %aten::batch_norm_34.running_var: Tensor[(256), float32] /* span=aten::batch_norm_34.running_var:0:0 */, %aten::_convolution_35.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_35.weight:0:0 */, %aten::batch_norm_35.weight: Tensor[(256), float32] /* span=aten::batch_norm_35.weight:0:0 */, %aten::batch_norm_35.bias: Tensor[(256), float32] /* span=aten::batch_norm_35.bias:0:0 */, %aten::batch_norm_35.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_35.running_mean:0:0 */, %aten::batch_norm_35.running_var: Tensor[(256), float32] /* span=aten::batch_norm_35.running_var:0:0 */, %aten::_convolution_36.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_36.weight:0:0 */, %aten::batch_norm_36.weight: Tensor[(1024), float32] /* span=aten::batch_norm_36.weight:0:0 */, %aten::batch_norm_36.bias: Tensor[(1024), float32] /* span=aten::batch_norm_36.bias:0:0 */, %aten::batch_norm_36.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_36.running_mean:0:0 */, %aten::batch_norm_36.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_36.running_var:0:0 */, %aten::_convolution_37.weight: Tensor[(256, 1024, 1, 1), float32] /* span=aten::_convolution_37.weight:0:0 */, %aten::batch_norm_37.weight: Tensor[(256), float32] /* span=aten::batch_norm_37.weight:0:0 */, %aten::batch_norm_37.bias: Tensor[(256), float32] /* span=aten::batch_norm_37.bias:0:0 */, %aten::batch_norm_37.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_37.running_mean:0:0 */, %aten::batch_norm_37.running_var: Tensor[(256), float32] /* span=aten::batch_norm_37.running_var:0:0 */, %aten::_convolution_38.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_38.weight:0:0 */, %aten::batch_norm_38.weight: Tensor[(256), float32] /* span=aten::batch_norm_38.weight:0:0 */, %aten::batch_norm_38.bias: Tensor[(256), float32] /* span=aten::batch_norm_38.bias:0:0 */, %aten::batch_norm_38.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_38.running_mean:0:0 */, %aten::batch_norm_38.running_var: Tensor[(256), float32] /* span=aten::batch_norm_38.running_var:0:0 */, %aten::_convolution_39.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_39.weight:0:0 */, %aten::batch_norm_39.weight: Tensor[(1024), float32] /* span=aten::batch_norm_39.weight:0:0 */, %aten::batch_norm_39.bias: Tensor[(1024), float32] /* span=aten::batch_norm_39.bias:0:0 */, %aten::batch_norm_39.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_39.running_mean:0:0 */, %aten::batch_norm_39.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_39.running_var:0:0 */, %aten::_convolution_40.weight: Tensor[(256, 1024, 1, 1), float32] /* span=aten::_convolution_40.weight:0:0 */, %aten::batch_norm_40.weight: Tensor[(256), float32] /* span=aten::batch_norm_40.weight:0:0 */, %aten::batch_norm_40.bias: Tensor[(256), float32] /* span=aten::batch_norm_40.bias:0:0 */, %aten::batch_norm_40.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_40.running_mean:0:0 */, %aten::batch_norm_40.running_var: Tensor[(256), float32] /* span=aten::batch_norm_40.running_var:0:0 */, %aten::_convolution_41.weight: Tensor[(256, 256, 3, 3), float32] /* span=aten::_convolution_41.weight:0:0 */, %aten::batch_norm_41.weight: Tensor[(256), float32] /* span=aten::batch_norm_41.weight:0:0 */, %aten::batch_norm_41.bias: Tensor[(256), float32] /* span=aten::batch_norm_41.bias:0:0 */, %aten::batch_norm_41.running_mean: Tensor[(256), float32] /* span=aten::batch_norm_41.running_mean:0:0 */, %aten::batch_norm_41.running_var: Tensor[(256), float32] /* span=aten::batch_norm_41.running_var:0:0 */, %aten::_convolution_42.weight: Tensor[(1024, 256, 1, 1), float32] /* span=aten::_convolution_42.weight:0:0 */, %aten::batch_norm_42.weight: Tensor[(1024), float32] /* span=aten::batch_norm_42.weight:0:0 */, %aten::batch_norm_42.bias: Tensor[(1024), float32] /* span=aten::batch_norm_42.bias:0:0 */, %aten::batch_norm_42.running_mean: Tensor[(1024), float32] /* span=aten::batch_norm_42.running_mean:0:0 */, %aten::batch_norm_42.running_var: Tensor[(1024), float32] /* span=aten::batch_norm_42.running_var:0:0 */, %aten::_convolution_43.weight: Tensor[(512, 1024, 1, 1), float32] /* span=aten::_convolution_43.weight:0:0 */, %aten::batch_norm_43.weight: Tensor[(512), float32] /* span=aten::batch_norm_43.weight:0:0 */, %aten::batch_norm_43.bias: Tensor[(512), float32] /* span=aten::batch_norm_43.bias:0:0 */, %aten::batch_norm_43.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_43.running_mean:0:0 */, %aten::batch_norm_43.running_var: Tensor[(512), float32] /* span=aten::batch_norm_43.running_var:0:0 */, %aten::_convolution_44.weight: Tensor[(512, 512, 3, 3), float32] /* span=aten::_convolution_44.weight:0:0 */, %aten::batch_norm_44.weight: Tensor[(512), float32] /* span=aten::batch_norm_44.weight:0:0 */, %aten::batch_norm_44.bias: Tensor[(512), float32] /* span=aten::batch_norm_44.bias:0:0 */, %aten::batch_norm_44.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_44.running_mean:0:0 */, %aten::batch_norm_44.running_var: Tensor[(512), float32] /* span=aten::batch_norm_44.running_var:0:0 */, %aten::_convolution_45.weight: Tensor[(2048, 512, 1, 1), float32] /* span=aten::_convolution_45.weight:0:0 */, %aten::batch_norm_45.weight: Tensor[(2048), float32] /* span=aten::batch_norm_45.weight:0:0 */, %aten::batch_norm_45.bias: Tensor[(2048), float32] /* span=aten::batch_norm_45.bias:0:0 */, %aten::batch_norm_45.running_mean: Tensor[(2048), float32] /* span=aten::batch_norm_45.running_mean:0:0 */, %aten::batch_norm_45.running_var: Tensor[(2048), float32] /* span=aten::batch_norm_45.running_var:0:0 */, %aten::_convolution_46.weight: Tensor[(2048, 1024, 1, 1), float32] /* span=aten::_convolution_46.weight:0:0 */, %aten::batch_norm_46.weight: Tensor[(2048), float32] /* span=aten::batch_norm_46.weight:0:0 */, %aten::batch_norm_46.bias: Tensor[(2048), float32] /* span=aten::batch_norm_46.bias:0:0 */, %aten::batch_norm_46.running_mean: Tensor[(2048), float32] /* span=aten::batch_norm_46.running_mean:0:0 */, %aten::batch_norm_46.running_var: Tensor[(2048), float32] /* span=aten::batch_norm_46.running_var:0:0 */, %aten::_convolution_47.weight: Tensor[(512, 2048, 1, 1), float32] /* span=aten::_convolution_47.weight:0:0 */, %aten::batch_norm_47.weight: Tensor[(512), float32] /* span=aten::batch_norm_47.weight:0:0 */, %aten::batch_norm_47.bias: Tensor[(512), float32] /* span=aten::batch_norm_47.bias:0:0 */, %aten::batch_norm_47.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_47.running_mean:0:0 */, %aten::batch_norm_47.running_var: Tensor[(512), float32] /* span=aten::batch_norm_47.running_var:0:0 */, %aten::_convolution_48.weight: Tensor[(512, 512, 3, 3), float32] /* span=aten::_convolution_48.weight:0:0 */, %aten::batch_norm_48.weight: Tensor[(512), float32] /* span=aten::batch_norm_48.weight:0:0 */, %aten::batch_norm_48.bias: Tensor[(512), float32] /* span=aten::batch_norm_48.bias:0:0 */, %aten::batch_norm_48.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_48.running_mean:0:0 */, %aten::batch_norm_48.running_var: Tensor[(512), float32] /* span=aten::batch_norm_48.running_var:0:0 */, %aten::_convolution_49.weight: Tensor[(2048, 512, 1, 1), float32] /* span=aten::_convolution_49.weight:0:0 */, %aten::batch_norm_49.weight: Tensor[(2048), float32] /* span=aten::batch_norm_49.weight:0:0 */, %aten::batch_norm_49.bias: Tensor[(2048), float32] /* span=aten::batch_norm_49.bias:0:0 */, %aten::batch_norm_49.running_mean: Tensor[(2048), float32] /* span=aten::batch_norm_49.running_mean:0:0 */, %aten::batch_norm_49.running_var: Tensor[(2048), float32] /* span=aten::batch_norm_49.running_var:0:0 */, %aten::_convolution_50.weight: Tensor[(512, 2048, 1, 1), float32] /* span=aten::_convolution_50.weight:0:0 */, %aten::batch_norm_50.weight: Tensor[(512), float32] /* span=aten::batch_norm_50.weight:0:0 */, %aten::batch_norm_50.bias: Tensor[(512), float32] /* span=aten::batch_norm_50.bias:0:0 */, %aten::batch_norm_50.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_50.running_mean:0:0 */, %aten::batch_norm_50.running_var: Tensor[(512), float32] /* span=aten::batch_norm_50.running_var:0:0 */, %aten::_convolution_51.weight: Tensor[(512, 512, 3, 3), float32] /* span=aten::_convolution_51.weight:0:0 */, %aten::batch_norm_51.weight: Tensor[(512), float32] /* span=aten::batch_norm_51.weight:0:0 */, %aten::batch_norm_51.bias: Tensor[(512), float32] /* span=aten::batch_norm_51.bias:0:0 */, %aten::batch_norm_51.running_mean: Tensor[(512), float32] /* span=aten::batch_norm_51.running_mean:0:0 */, %aten::batch_norm_51.running_var: Tensor[(512), float32] /* span=aten::batch_norm_51.running_var:0:0 */, %aten::_convolution_52.weight: Tensor[(2048, 512, 1, 1), float32] /* span=aten::_convolution_52.weight:0:0 */, %aten::batch_norm_52.weight: Tensor[(2048), float32] /* span=aten::batch_norm_52.weight:0:0 */, %aten::batch_norm_52.bias: Tensor[(2048), float32] /* span=aten::batch_norm_52.bias:0:0 */, %aten::batch_norm_52.running_mean: Tensor[(2048), float32] /* span=aten::batch_norm_52.running_mean:0:0 */, %aten::batch_norm_52.running_var: Tensor[(2048), float32] /* span=aten::batch_norm_52.running_var:0:0 */, %aten::linear_0.weight: Tensor[(1000, 2048), float32] /* span=aten::linear_0.weight:0:0 */, %aten::linear_0.bias: Tensor[(1000), float32] /* span=aten::linear_0.bias:0:0 */) {
  %0 = nn.conv2d(%input, %aten::_convolution_0.weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* span=aten::_convolution_0:0:0 */;
  %1 = nn.batch_norm(%0, %aten::batch_norm_0.weight, %aten::batch_norm_0.bias, %aten::batch_norm_0.running_mean, %aten::batch_norm_0.running_var) /* span=aten::batch_norm_0:0:0 */;
  %2 = %1.0 /* span=aten::batch_norm_0:0:0 */;
  %3 = nn.relu(%2) /* span=aten::relu__0:0:0 */;
  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* span=aten::max_pool2d_0:0:0 */;
  %5 = nn.conv2d(%4, %aten::_convolution_1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* span=aten::_convolution_1:0:0 */;
  %6 = nn.batch_norm(%5, %aten::batch_norm_1.weight, %aten::batch_norm_1.bias, %aten::batch_norm_1.running_mean, %aten::batch_norm_1.running_var) /* span=aten::batch_norm_1:0:0 */;
  %7 = %6.0 /* span=aten::batch_norm_1:0:0 */;
  %8 = nn.relu(%7) /* span=aten::relu__1:0:0 */;
  %9 = nn.conv2d(%8, %aten::_convolution_2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_2:0:0 */;
  %10 = nn.batch_norm(%9, %aten::batch_norm_2.weight, %aten::batch_norm_2.bias, %aten::batch_norm_2.running_mean, %aten::batch_norm_2.running_var) /* span=aten::batch_norm_2:0:0 */;
  %11 = %10.0 /* span=aten::batch_norm_2:0:0 */;
  %12 = nn.relu(%11) /* span=aten::relu__2:0:0 */;
  %13 = nn.conv2d(%12, %aten::_convolution_3.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_3:0:0 */;
  %14 = nn.batch_norm(%13, %aten::batch_norm_3.weight, %aten::batch_norm_3.bias, %aten::batch_norm_3.running_mean, %aten::batch_norm_3.running_var) /* span=aten::batch_norm_3:0:0 */;
  %15 = nn.conv2d(%4, %aten::_convolution_4.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_4:0:0 */;
  %16 = nn.batch_norm(%15, %aten::batch_norm_4.weight, %aten::batch_norm_4.bias, %aten::batch_norm_4.running_mean, %aten::batch_norm_4.running_var) /* span=aten::batch_norm_4:0:0 */;
  %17 = %14.0 /* span=aten::batch_norm_3:0:0 */;
  %18 = %16.0 /* span=aten::batch_norm_4:0:0 */;
  %19 = add(%17, %18) /* span=aten::add__0:0:0 */;
  %20 = nn.relu(%19) /* span=aten::relu__3:0:0 */;
  %21 = nn.conv2d(%20, %aten::_convolution_5.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* span=aten::_convolution_5:0:0 */;
  %22 = nn.batch_norm(%21, %aten::batch_norm_5.weight, %aten::batch_norm_5.bias, %aten::batch_norm_5.running_mean, %aten::batch_norm_5.running_var) /* span=aten::batch_norm_5:0:0 */;
  %23 = %22.0 /* span=aten::batch_norm_5:0:0 */;
  %24 = nn.relu(%23) /* span=aten::relu__4:0:0 */;
  %25 = nn.conv2d(%24, %aten::_convolution_6.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_6:0:0 */;
  %26 = nn.batch_norm(%25, %aten::batch_norm_6.weight, %aten::batch_norm_6.bias, %aten::batch_norm_6.running_mean, %aten::batch_norm_6.running_var) /* span=aten::batch_norm_6:0:0 */;
  %27 = %26.0 /* span=aten::batch_norm_6:0:0 */;
  %28 = nn.relu(%27) /* span=aten::relu__5:0:0 */;
  %29 = nn.conv2d(%28, %aten::_convolution_7.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_7:0:0 */;
  %30 = nn.batch_norm(%29, %aten::batch_norm_7.weight, %aten::batch_norm_7.bias, %aten::batch_norm_7.running_mean, %aten::batch_norm_7.running_var) /* span=aten::batch_norm_7:0:0 */;
  %31 = %30.0 /* span=aten::batch_norm_7:0:0 */;
  %32 = add(%31, %20) /* span=aten::add__1:0:0 */;
  %33 = nn.relu(%32) /* span=aten::relu__6:0:0 */;
  %34 = nn.conv2d(%33, %aten::_convolution_8.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* span=aten::_convolution_8:0:0 */;
  %35 = nn.batch_norm(%34, %aten::batch_norm_8.weight, %aten::batch_norm_8.bias, %aten::batch_norm_8.running_mean, %aten::batch_norm_8.running_var) /* span=aten::batch_norm_8:0:0 */;
  %36 = %35.0 /* span=aten::batch_norm_8:0:0 */;
  %37 = nn.relu(%36) /* span=aten::relu__7:0:0 */;
  %38 = nn.conv2d(%37, %aten::_convolution_9.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_9:0:0 */;
  %39 = nn.batch_norm(%38, %aten::batch_norm_9.weight, %aten::batch_norm_9.bias, %aten::batch_norm_9.running_mean, %aten::batch_norm_9.running_var) /* span=aten::batch_norm_9:0:0 */;
  %40 = %39.0 /* span=aten::batch_norm_9:0:0 */;
  %41 = nn.relu(%40) /* span=aten::relu__8:0:0 */;
  %42 = nn.conv2d(%41, %aten::_convolution_10.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_10:0:0 */;
  %43 = nn.batch_norm(%42, %aten::batch_norm_10.weight, %aten::batch_norm_10.bias, %aten::batch_norm_10.running_mean, %aten::batch_norm_10.running_var) /* span=aten::batch_norm_10:0:0 */;
  %44 = %43.0 /* span=aten::batch_norm_10:0:0 */;
  %45 = add(%44, %33) /* span=aten::add__2:0:0 */;
  %46 = nn.relu(%45) /* span=aten::relu__9:0:0 */;
  %47 = nn.conv2d(%46, %aten::_convolution_11.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* span=aten::_convolution_11:0:0 */;
  %48 = nn.batch_norm(%47, %aten::batch_norm_11.weight, %aten::batch_norm_11.bias, %aten::batch_norm_11.running_mean, %aten::batch_norm_11.running_var) /* span=aten::batch_norm_11:0:0 */;
  %49 = %48.0 /* span=aten::batch_norm_11:0:0 */;
  %50 = nn.relu(%49) /* span=aten::relu__10:0:0 */;
  %51 = nn.conv2d(%50, %aten::_convolution_12.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* span=aten::_convolution_12:0:0 */;
  %52 = nn.batch_norm(%51, %aten::batch_norm_12.weight, %aten::batch_norm_12.bias, %aten::batch_norm_12.running_mean, %aten::batch_norm_12.running_var) /* span=aten::batch_norm_12:0:0 */;
  %53 = %52.0 /* span=aten::batch_norm_12:0:0 */;
  %54 = nn.relu(%53) /* span=aten::relu__11:0:0 */;
  %55 = nn.conv2d(%54, %aten::_convolution_13.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_13:0:0 */;
  %56 = nn.batch_norm(%55, %aten::batch_norm_13.weight, %aten::batch_norm_13.bias, %aten::batch_norm_13.running_mean, %aten::batch_norm_13.running_var) /* span=aten::batch_norm_13:0:0 */;
  %57 = nn.conv2d(%46, %aten::_convolution_14.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_14:0:0 */;
  %58 = nn.batch_norm(%57, %aten::batch_norm_14.weight, %aten::batch_norm_14.bias, %aten::batch_norm_14.running_mean, %aten::batch_norm_14.running_var) /* span=aten::batch_norm_14:0:0 */;
  %59 = %56.0 /* span=aten::batch_norm_13:0:0 */;
  %60 = %58.0 /* span=aten::batch_norm_14:0:0 */;
  %61 = add(%59, %60) /* span=aten::add__3:0:0 */;
  %62 = nn.relu(%61) /* span=aten::relu__12:0:0 */;
  %63 = nn.conv2d(%62, %aten::_convolution_15.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* span=aten::_convolution_15:0:0 */;
  %64 = nn.batch_norm(%63, %aten::batch_norm_15.weight, %aten::batch_norm_15.bias, %aten::batch_norm_15.running_mean, %aten::batch_norm_15.running_var) /* span=aten::batch_norm_15:0:0 */;
  %65 = %64.0 /* span=aten::batch_norm_15:0:0 */;
  %66 = nn.relu(%65) /* span=aten::relu__13:0:0 */;
  %67 = nn.conv2d(%66, %aten::_convolution_16.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* span=aten::_convolution_16:0:0 */;
  %68 = nn.batch_norm(%67, %aten::batch_norm_16.weight, %aten::batch_norm_16.bias, %aten::batch_norm_16.running_mean, %aten::batch_norm_16.running_var) /* span=aten::batch_norm_16:0:0 */;
  %69 = %68.0 /* span=aten::batch_norm_16:0:0 */;
  %70 = nn.relu(%69) /* span=aten::relu__14:0:0 */;
  %71 = nn.conv2d(%70, %aten::_convolution_17.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_17:0:0 */;
  %72 = nn.batch_norm(%71, %aten::batch_norm_17.weight, %aten::batch_norm_17.bias, %aten::batch_norm_17.running_mean, %aten::batch_norm_17.running_var) /* span=aten::batch_norm_17:0:0 */;
  %73 = %72.0 /* span=aten::batch_norm_17:0:0 */;
  %74 = add(%73, %62) /* span=aten::add__4:0:0 */;
  %75 = nn.relu(%74) /* span=aten::relu__15:0:0 */;
  %76 = nn.conv2d(%75, %aten::_convolution_18.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* span=aten::_convolution_18:0:0 */;
  %77 = nn.batch_norm(%76, %aten::batch_norm_18.weight, %aten::batch_norm_18.bias, %aten::batch_norm_18.running_mean, %aten::batch_norm_18.running_var) /* span=aten::batch_norm_18:0:0 */;
  %78 = %77.0 /* span=aten::batch_norm_18:0:0 */;
  %79 = nn.relu(%78) /* span=aten::relu__16:0:0 */;
  %80 = nn.conv2d(%79, %aten::_convolution_19.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* span=aten::_convolution_19:0:0 */;
  %81 = nn.batch_norm(%80, %aten::batch_norm_19.weight, %aten::batch_norm_19.bias, %aten::batch_norm_19.running_mean, %aten::batch_norm_19.running_var) /* span=aten::batch_norm_19:0:0 */;
  %82 = %81.0 /* span=aten::batch_norm_19:0:0 */;
  %83 = nn.relu(%82) /* span=aten::relu__17:0:0 */;
  %84 = nn.conv2d(%83, %aten::_convolution_20.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_20:0:0 */;
  %85 = nn.batch_norm(%84, %aten::batch_norm_20.weight, %aten::batch_norm_20.bias, %aten::batch_norm_20.running_mean, %aten::batch_norm_20.running_var) /* span=aten::batch_norm_20:0:0 */;
  %86 = %85.0 /* span=aten::batch_norm_20:0:0 */;
  %87 = add(%86, %75) /* span=aten::add__5:0:0 */;
  %88 = nn.relu(%87) /* span=aten::relu__18:0:0 */;
  %89 = nn.conv2d(%88, %aten::_convolution_21.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* span=aten::_convolution_21:0:0 */;
  %90 = nn.batch_norm(%89, %aten::batch_norm_21.weight, %aten::batch_norm_21.bias, %aten::batch_norm_21.running_mean, %aten::batch_norm_21.running_var) /* span=aten::batch_norm_21:0:0 */;
  %91 = %90.0 /* span=aten::batch_norm_21:0:0 */;
  %92 = nn.relu(%91) /* span=aten::relu__19:0:0 */;
  %93 = nn.conv2d(%92, %aten::_convolution_22.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* span=aten::_convolution_22:0:0 */;
  %94 = nn.batch_norm(%93, %aten::batch_norm_22.weight, %aten::batch_norm_22.bias, %aten::batch_norm_22.running_mean, %aten::batch_norm_22.running_var) /* span=aten::batch_norm_22:0:0 */;
  %95 = %94.0 /* span=aten::batch_norm_22:0:0 */;
  %96 = nn.relu(%95) /* span=aten::relu__20:0:0 */;
  %97 = nn.conv2d(%96, %aten::_convolution_23.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_23:0:0 */;
  %98 = nn.batch_norm(%97, %aten::batch_norm_23.weight, %aten::batch_norm_23.bias, %aten::batch_norm_23.running_mean, %aten::batch_norm_23.running_var) /* span=aten::batch_norm_23:0:0 */;
  %99 = %98.0 /* span=aten::batch_norm_23:0:0 */;
  %100 = add(%99, %88) /* span=aten::add__6:0:0 */;
  %101 = nn.relu(%100) /* span=aten::relu__21:0:0 */;
  %102 = nn.conv2d(%101, %aten::_convolution_24.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_24:0:0 */;
  %103 = nn.batch_norm(%102, %aten::batch_norm_24.weight, %aten::batch_norm_24.bias, %aten::batch_norm_24.running_mean, %aten::batch_norm_24.running_var) /* span=aten::batch_norm_24:0:0 */;
  %104 = %103.0 /* span=aten::batch_norm_24:0:0 */;
  %105 = nn.relu(%104) /* span=aten::relu__22:0:0 */;
  %106 = nn.conv2d(%105, %aten::_convolution_25.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_25:0:0 */;
  %107 = nn.batch_norm(%106, %aten::batch_norm_25.weight, %aten::batch_norm_25.bias, %aten::batch_norm_25.running_mean, %aten::batch_norm_25.running_var) /* span=aten::batch_norm_25:0:0 */;
  %108 = %107.0 /* span=aten::batch_norm_25:0:0 */;
  %109 = nn.relu(%108) /* span=aten::relu__23:0:0 */;
  %110 = nn.conv2d(%109, %aten::_convolution_26.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_26:0:0 */;
  %111 = nn.batch_norm(%110, %aten::batch_norm_26.weight, %aten::batch_norm_26.bias, %aten::batch_norm_26.running_mean, %aten::batch_norm_26.running_var) /* span=aten::batch_norm_26:0:0 */;
  %112 = nn.conv2d(%101, %aten::_convolution_27.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_27:0:0 */;
  %113 = nn.batch_norm(%112, %aten::batch_norm_27.weight, %aten::batch_norm_27.bias, %aten::batch_norm_27.running_mean, %aten::batch_norm_27.running_var) /* span=aten::batch_norm_27:0:0 */;
  %114 = %111.0 /* span=aten::batch_norm_26:0:0 */;
  %115 = %113.0 /* span=aten::batch_norm_27:0:0 */;
  %116 = add(%114, %115) /* span=aten::add__7:0:0 */;
  %117 = nn.relu(%116) /* span=aten::relu__24:0:0 */;
  %118 = nn.conv2d(%117, %aten::_convolution_28.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_28:0:0 */;
  %119 = nn.batch_norm(%118, %aten::batch_norm_28.weight, %aten::batch_norm_28.bias, %aten::batch_norm_28.running_mean, %aten::batch_norm_28.running_var) /* span=aten::batch_norm_28:0:0 */;
  %120 = %119.0 /* span=aten::batch_norm_28:0:0 */;
  %121 = nn.relu(%120) /* span=aten::relu__25:0:0 */;
  %122 = nn.conv2d(%121, %aten::_convolution_29.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_29:0:0 */;
  %123 = nn.batch_norm(%122, %aten::batch_norm_29.weight, %aten::batch_norm_29.bias, %aten::batch_norm_29.running_mean, %aten::batch_norm_29.running_var) /* span=aten::batch_norm_29:0:0 */;
  %124 = %123.0 /* span=aten::batch_norm_29:0:0 */;
  %125 = nn.relu(%124) /* span=aten::relu__26:0:0 */;
  %126 = nn.conv2d(%125, %aten::_convolution_30.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_30:0:0 */;
  %127 = nn.batch_norm(%126, %aten::batch_norm_30.weight, %aten::batch_norm_30.bias, %aten::batch_norm_30.running_mean, %aten::batch_norm_30.running_var) /* span=aten::batch_norm_30:0:0 */;
  %128 = %127.0 /* span=aten::batch_norm_30:0:0 */;
  %129 = add(%128, %117) /* span=aten::add__8:0:0 */;
  %130 = nn.relu(%129) /* span=aten::relu__27:0:0 */;
  %131 = nn.conv2d(%130, %aten::_convolution_31.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_31:0:0 */;
  %132 = nn.batch_norm(%131, %aten::batch_norm_31.weight, %aten::batch_norm_31.bias, %aten::batch_norm_31.running_mean, %aten::batch_norm_31.running_var) /* span=aten::batch_norm_31:0:0 */;
  %133 = %132.0 /* span=aten::batch_norm_31:0:0 */;
  %134 = nn.relu(%133) /* span=aten::relu__28:0:0 */;
  %135 = nn.conv2d(%134, %aten::_convolution_32.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_32:0:0 */;
  %136 = nn.batch_norm(%135, %aten::batch_norm_32.weight, %aten::batch_norm_32.bias, %aten::batch_norm_32.running_mean, %aten::batch_norm_32.running_var) /* span=aten::batch_norm_32:0:0 */;
  %137 = %136.0 /* span=aten::batch_norm_32:0:0 */;
  %138 = nn.relu(%137) /* span=aten::relu__29:0:0 */;
  %139 = nn.conv2d(%138, %aten::_convolution_33.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_33:0:0 */;
  %140 = nn.batch_norm(%139, %aten::batch_norm_33.weight, %aten::batch_norm_33.bias, %aten::batch_norm_33.running_mean, %aten::batch_norm_33.running_var) /* span=aten::batch_norm_33:0:0 */;
  %141 = %140.0 /* span=aten::batch_norm_33:0:0 */;
  %142 = add(%141, %130) /* span=aten::add__9:0:0 */;
  %143 = nn.relu(%142) /* span=aten::relu__30:0:0 */;
  %144 = nn.conv2d(%143, %aten::_convolution_34.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_34:0:0 */;
  %145 = nn.batch_norm(%144, %aten::batch_norm_34.weight, %aten::batch_norm_34.bias, %aten::batch_norm_34.running_mean, %aten::batch_norm_34.running_var) /* span=aten::batch_norm_34:0:0 */;
  %146 = %145.0 /* span=aten::batch_norm_34:0:0 */;
  %147 = nn.relu(%146) /* span=aten::relu__31:0:0 */;
  %148 = nn.conv2d(%147, %aten::_convolution_35.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_35:0:0 */;
  %149 = nn.batch_norm(%148, %aten::batch_norm_35.weight, %aten::batch_norm_35.bias, %aten::batch_norm_35.running_mean, %aten::batch_norm_35.running_var) /* span=aten::batch_norm_35:0:0 */;
  %150 = %149.0 /* span=aten::batch_norm_35:0:0 */;
  %151 = nn.relu(%150) /* span=aten::relu__32:0:0 */;
  %152 = nn.conv2d(%151, %aten::_convolution_36.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_36:0:0 */;
  %153 = nn.batch_norm(%152, %aten::batch_norm_36.weight, %aten::batch_norm_36.bias, %aten::batch_norm_36.running_mean, %aten::batch_norm_36.running_var) /* span=aten::batch_norm_36:0:0 */;
  %154 = %153.0 /* span=aten::batch_norm_36:0:0 */;
  %155 = add(%154, %143) /* span=aten::add__10:0:0 */;
  %156 = nn.relu(%155) /* span=aten::relu__33:0:0 */;
  %157 = nn.conv2d(%156, %aten::_convolution_37.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_37:0:0 */;
  %158 = nn.batch_norm(%157, %aten::batch_norm_37.weight, %aten::batch_norm_37.bias, %aten::batch_norm_37.running_mean, %aten::batch_norm_37.running_var) /* span=aten::batch_norm_37:0:0 */;
  %159 = %158.0 /* span=aten::batch_norm_37:0:0 */;
  %160 = nn.relu(%159) /* span=aten::relu__34:0:0 */;
  %161 = nn.conv2d(%160, %aten::_convolution_38.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_38:0:0 */;
  %162 = nn.batch_norm(%161, %aten::batch_norm_38.weight, %aten::batch_norm_38.bias, %aten::batch_norm_38.running_mean, %aten::batch_norm_38.running_var) /* span=aten::batch_norm_38:0:0 */;
  %163 = %162.0 /* span=aten::batch_norm_38:0:0 */;
  %164 = nn.relu(%163) /* span=aten::relu__35:0:0 */;
  %165 = nn.conv2d(%164, %aten::_convolution_39.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_39:0:0 */;
  %166 = nn.batch_norm(%165, %aten::batch_norm_39.weight, %aten::batch_norm_39.bias, %aten::batch_norm_39.running_mean, %aten::batch_norm_39.running_var) /* span=aten::batch_norm_39:0:0 */;
  %167 = %166.0 /* span=aten::batch_norm_39:0:0 */;
  %168 = add(%167, %156) /* span=aten::add__11:0:0 */;
  %169 = nn.relu(%168) /* span=aten::relu__36:0:0 */;
  %170 = nn.conv2d(%169, %aten::_convolution_40.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* span=aten::_convolution_40:0:0 */;
  %171 = nn.batch_norm(%170, %aten::batch_norm_40.weight, %aten::batch_norm_40.bias, %aten::batch_norm_40.running_mean, %aten::batch_norm_40.running_var) /* span=aten::batch_norm_40:0:0 */;
  %172 = %171.0 /* span=aten::batch_norm_40:0:0 */;
  %173 = nn.relu(%172) /* span=aten::relu__37:0:0 */;
  %174 = nn.conv2d(%173, %aten::_convolution_41.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* span=aten::_convolution_41:0:0 */;
  %175 = nn.batch_norm(%174, %aten::batch_norm_41.weight, %aten::batch_norm_41.bias, %aten::batch_norm_41.running_mean, %aten::batch_norm_41.running_var) /* span=aten::batch_norm_41:0:0 */;
  %176 = %175.0 /* span=aten::batch_norm_41:0:0 */;
  %177 = nn.relu(%176) /* span=aten::relu__38:0:0 */;
  %178 = nn.conv2d(%177, %aten::_convolution_42.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* span=aten::_convolution_42:0:0 */;
  %179 = nn.batch_norm(%178, %aten::batch_norm_42.weight, %aten::batch_norm_42.bias, %aten::batch_norm_42.running_mean, %aten::batch_norm_42.running_var) /* span=aten::batch_norm_42:0:0 */;
  %180 = %179.0 /* span=aten::batch_norm_42:0:0 */;
  %181 = add(%180, %169) /* span=aten::add__12:0:0 */;
  %182 = nn.relu(%181) /* span=aten::relu__39:0:0 */;
  %183 = nn.conv2d(%182, %aten::_convolution_43.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_43:0:0 */;
  %184 = nn.batch_norm(%183, %aten::batch_norm_43.weight, %aten::batch_norm_43.bias, %aten::batch_norm_43.running_mean, %aten::batch_norm_43.running_var) /* span=aten::batch_norm_43:0:0 */;
  %185 = %184.0 /* span=aten::batch_norm_43:0:0 */;
  %186 = nn.relu(%185) /* span=aten::relu__40:0:0 */;
  %187 = nn.conv2d(%186, %aten::_convolution_44.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* span=aten::_convolution_44:0:0 */;
  %188 = nn.batch_norm(%187, %aten::batch_norm_44.weight, %aten::batch_norm_44.bias, %aten::batch_norm_44.running_mean, %aten::batch_norm_44.running_var) /* span=aten::batch_norm_44:0:0 */;
  %189 = %188.0 /* span=aten::batch_norm_44:0:0 */;
  %190 = nn.relu(%189) /* span=aten::relu__41:0:0 */;
  %191 = nn.conv2d(%190, %aten::_convolution_45.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* span=aten::_convolution_45:0:0 */;
  %192 = nn.batch_norm(%191, %aten::batch_norm_45.weight, %aten::batch_norm_45.bias, %aten::batch_norm_45.running_mean, %aten::batch_norm_45.running_var) /* span=aten::batch_norm_45:0:0 */;
  %193 = nn.conv2d(%182, %aten::_convolution_46.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* span=aten::_convolution_46:0:0 */;
  %194 = nn.batch_norm(%193, %aten::batch_norm_46.weight, %aten::batch_norm_46.bias, %aten::batch_norm_46.running_mean, %aten::batch_norm_46.running_var) /* span=aten::batch_norm_46:0:0 */;
  %195 = %192.0 /* span=aten::batch_norm_45:0:0 */;
  %196 = %194.0 /* span=aten::batch_norm_46:0:0 */;
  %197 = add(%195, %196) /* span=aten::add__13:0:0 */;
  %198 = nn.relu(%197) /* span=aten::relu__42:0:0 */;
  %199 = nn.conv2d(%198, %aten::_convolution_47.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_47:0:0 */;
  %200 = nn.batch_norm(%199, %aten::batch_norm_47.weight, %aten::batch_norm_47.bias, %aten::batch_norm_47.running_mean, %aten::batch_norm_47.running_var) /* span=aten::batch_norm_47:0:0 */;
  %201 = %200.0 /* span=aten::batch_norm_47:0:0 */;
  %202 = nn.relu(%201) /* span=aten::relu__43:0:0 */;
  %203 = nn.conv2d(%202, %aten::_convolution_48.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* span=aten::_convolution_48:0:0 */;
  %204 = nn.batch_norm(%203, %aten::batch_norm_48.weight, %aten::batch_norm_48.bias, %aten::batch_norm_48.running_mean, %aten::batch_norm_48.running_var) /* span=aten::batch_norm_48:0:0 */;
  %205 = %204.0 /* span=aten::batch_norm_48:0:0 */;
  %206 = nn.relu(%205) /* span=aten::relu__44:0:0 */;
  %207 = nn.conv2d(%206, %aten::_convolution_49.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* span=aten::_convolution_49:0:0 */;
  %208 = nn.batch_norm(%207, %aten::batch_norm_49.weight, %aten::batch_norm_49.bias, %aten::batch_norm_49.running_mean, %aten::batch_norm_49.running_var) /* span=aten::batch_norm_49:0:0 */;
  %209 = %208.0 /* span=aten::batch_norm_49:0:0 */;
  %210 = add(%209, %198) /* span=aten::add__14:0:0 */;
  %211 = nn.relu(%210) /* span=aten::relu__45:0:0 */;
  %212 = nn.conv2d(%211, %aten::_convolution_50.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* span=aten::_convolution_50:0:0 */;
  %213 = nn.batch_norm(%212, %aten::batch_norm_50.weight, %aten::batch_norm_50.bias, %aten::batch_norm_50.running_mean, %aten::batch_norm_50.running_var) /* span=aten::batch_norm_50:0:0 */;
  %214 = %213.0 /* span=aten::batch_norm_50:0:0 */;
  %215 = nn.relu(%214) /* span=aten::relu__46:0:0 */;
  %216 = nn.conv2d(%215, %aten::_convolution_51.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* span=aten::_convolution_51:0:0 */;
  %217 = nn.batch_norm(%216, %aten::batch_norm_51.weight, %aten::batch_norm_51.bias, %aten::batch_norm_51.running_mean, %aten::batch_norm_51.running_var) /* span=aten::batch_norm_51:0:0 */;
  %218 = %217.0 /* span=aten::batch_norm_51:0:0 */;
  %219 = nn.relu(%218) /* span=aten::relu__47:0:0 */;
  %220 = nn.conv2d(%219, %aten::_convolution_52.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* span=aten::_convolution_52:0:0 */;
  %221 = nn.batch_norm(%220, %aten::batch_norm_52.weight, %aten::batch_norm_52.bias, %aten::batch_norm_52.running_mean, %aten::batch_norm_52.running_var) /* span=aten::batch_norm_52:0:0 */;
  %222 = %221.0 /* span=aten::batch_norm_52:0:0 */;
  %223 = add(%222, %211) /* span=aten::add__15:0:0 */;
  %224 = nn.relu(%223) /* span=aten::relu__48:0:0 */;
  %225 = nn.adaptive_avg_pool2d(%224, output_size=[1, 1]) /* span=aten::adaptive_avg_pool2d_0:0:0 */;
  %226 = reshape(%225, newshape=[0, -1, 1, 1]) /* span=aten::flatten_0:0:0 */;
  %227 = squeeze(%226, axis=[2, 3]) /* span=aten::flatten_0:0:0 */;
  %228 = nn.dense(%227, %aten::linear_0.weight, units=None) /* span=aten::linear_0:0:0 */;
  nn.bias_add(%228, %aten::linear_0.bias, axis=-1) /* span=aten::linear_0:0:0 */
}
</pre></div>
</div>
</section>
<section id="autotuning">
<h2>AutoTuning<a class="headerlink" href="#autotuning" title="Link to this heading"></a></h2>
<p>Now, the below api can be used for autotuning the model for any target.
Tuning required RPC setup and please refer to
<a class="reference external" href="https://tvm.apache.org/docs/how_to/deploy/adreno.html">Deploy to Adreno GPU</a></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_TRACKER_HOST&quot;</span><span class="p">,</span> <span class="s2">&quot;127.0.0.1&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TVM_TRACKER_PORT&quot;</span><span class="p">,</span> <span class="mi">9190</span><span class="p">))</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_key</span></a> <span class="o">=</span> <span class="s2">&quot;android&quot;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a><span class="p">)</span>

<span class="c1"># Auto tuning is compute intensive and time taking task.</span>
<span class="c1"># It is set to False in above configuration as this script runs in x86 for demonstration.</span>
<span class="c1"># Please to set :code:`is_tuning` to True to enable auto tuning.</span>

<span class="c1"># Also, :code:`test_target` is set to :code:`llvm` as this example to make compatible for x86 demonstration.</span>
<span class="c1"># Please change it to :code:`opencl` or :code:`opencl -device=adreno` for RPC target in configuration above.</span>

<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">is_tuning</span></a><span class="p">:</span>
    <span class="n">tvmc</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span>
        <span class="n">tvmc_model</span><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span>
        <span class="n">tuning_records</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_log</span></a><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="p">,</span>
        <span class="n">hostname</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_key</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_key</span></a><span class="p">,</span>
        <span class="n">tuner</span><span class="o">=</span><span class="s2">&quot;xgb&quot;</span><span class="p">,</span>
        <span class="n">repeat</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">trials</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compilation">
<h2>Compilation<a class="headerlink" href="#compilation" title="Link to this heading"></a></h2>
<p>Compilation to produce tvm artifacts</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># This generated example running on our x86 server for demonstration.</span>
<span class="c1"># To deply and tun on real target over RPC please set :code:`local_demo` to False in above configuration sestion.</span>

<span class="c1"># OpenCLML offloading will try to accelerate supported operators by using OpenCLML proprietory operator library.</span>
<span class="c1"># By default :code:`enable_clml` is set to False in above configuration section.</span>

<span class="k">if</span> <span class="ow">not</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">enable_clml</span></a><span class="p">:</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a><span class="p">:</span>
        <span class="n">tvmc_package</span> <span class="o">=</span> <span class="n">tvmc</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="n">tvmc_model</span><span class="p">,</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tvmc_package</span> <span class="o">=</span> <span class="n">tvmc</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="n">tvmc_model</span><span class="p">,</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="p">,</span>
            <span class="n">cross</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cross_compiler</span></a><span class="p">,</span>
            <span class="n">tuning_records</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_log</span></a><span class="p">,</span>
        <span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Altrernatively, we can save the compilation output and save it as a TVMCPackage.</span>
    <span class="c1"># This way avoids loading of compiled module without compiling again.</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">+</span> <span class="s2">&quot;, clml&quot;</span>
    <span class="n">pkg_path</span> <span class="o">=</span> <span class="n">tmp_path</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="s2">&quot;torch-resnet50.tar&quot;</span><span class="p">)</span>
    <span class="n">tvmc</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">tvmc_model</span><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target_host</span></a><span class="p">,</span>
        <span class="n">cross</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cross_compiler</span></a><span class="p">,</span>
        <span class="n">tuning_records</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_log</span></a><span class="p">,</span>
        <span class="n">package_path</span><span class="o">=</span><span class="n">pkg_path</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Load the compiled package</span>
    <span class="n">tvmc_package</span> <span class="o">=</span> <span class="n">TVMCPackage</span><span class="p">(</span><span class="n">package_path</span><span class="o">=</span><span class="n">pkg_path</span><span class="p">)</span>

<span class="c1"># tvmc_package consists of tvmc_package.lib_path, tvmc_package.graph, tvmc_package.params</span>
<span class="c1"># Saved TVMPackage is nothing but tar archive with mod.so, mod.json and mod.params.</span>
</pre></div>
</div>
</section>
<section id="deploy-run">
<h2>Deploy &amp; Run<a class="headerlink" href="#deploy-run" title="Link to this heading"></a></h2>
<p>Deploy and run the compiled model on RPC
Let tvmc fill inputs using random</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run on RPC setup</span>
<span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">local_demo</span></a><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tvmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tvmc_package</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">fill_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tvmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">tvmc_package</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cl&quot;</span><span class="p">,</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_key</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_key</span></a><span class="p">,</span>
        <span class="n">hostname</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_host</span></a><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rpc_tracker_port</span></a><span class="p">,</span>
        <span class="n">fill_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="p">)</span>

<span class="c1"># result is a dictionary of outputs.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Result:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Result: []
Output Names:
 [&#39;output_0&#39;]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 6.269 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-deploy-models-deploy-model-on-adreno-tvmc-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/613e0775d8981e544e6ca9602a975916/deploy_model_on_adreno_tvmc.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_model_on_adreno_tvmc.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f84e457773d8f292bfac905e2ed3307f/deploy_model_on_adreno_tvmc.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_model_on_adreno_tvmc.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ca68d46947b37488e0485162d60ff73d/deploy_model_on_adreno_tvmc.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">deploy_model_on_adreno_tvmc.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="deploy_model_on_android.html" class="btn btn-neutral float-right" title="Deploy the Pretrained Model on Android" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="deploy_model_on_adreno.html" class="btn btn-neutral float-left" title="Deploy the Pretrained Model on Adreno™" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2024 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2024 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>